{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdf36480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "import numpy.matlib\n",
    "import numpy as np\n",
    "import cv2\n",
    "import re\n",
    "from termcolor import colored\n",
    "from PIL import Image\n",
    "from typing import List\n",
    "from random import choices\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torchvision\n",
    "#check init out!\n",
    "import torch.nn.init as init\n",
    "import math\n",
    "\n",
    "#import torchvision  #for deformconv2\n",
    "\n",
    "import random\n",
    "import configparser\n",
    "from typing import Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from guided_filter_pytorch.guided_filter import GuidedFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0989e9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KITTI, MB or ETH\n",
    "dataset = 'MB'\n",
    "#used as prefix for saved weights\n",
    "model_name = 'mb_60f40s'\n",
    "\n",
    "#folder with training data\n",
    "#input_folder = '/media/HDD/TrainingsData/kitti2012/training/'\n",
    "\n",
    "#input_folder = '/media/HDD/TrainingsData/kitti2015/training/'\n",
    "\n",
    "#input_folder = '/media/HDD/TrainingsData/MB_H/trainingHDispEL/*/'\n",
    "\n",
    "#input_folder = '/media/HDD/Self-Sup_Stereo/OwnStereoNW/Out/Train/post-proc/NewTrainset/trainingHDisp/*/'\n",
    "\n",
    "#input_folder = '/media/HDD/TrainingsData/MB_H/trainingHDispRef/*/'\n",
    "\n",
    "input_folder = '/media/HDD/Self-Sup-Github/SAda-Net/TrainingRef/*'\n",
    "\n",
    "save_folder_branch = '/media/HDD/Self-Sup-Github/SAda-Net/weights/Trained/branch/'\n",
    "save_folder_simb = '/media/HDD/Self-Sup-Github/SAda-Net/weights/Trained/simB/'\n",
    "\n",
    "\n",
    "save_folder_branchdisp = '/media/HDD/Self-Sup-Github/SAda-Net/weights/Trained/branchDisp/'\n",
    "save_folder_branchim = '/media/HDD/Self-Sup-Github/SAda-Net/weights/Trained/branchIm/'\n",
    "save_folder_refine = '/media/HDD/Self-Sup-Github/SAda-Net/weights/Trained/refClass/'\n",
    "w_reg_folder = '/media/HDD/Self-Sup-Github/SAda-Net/weights/Trained/refReg/'\n",
    "\n",
    "\n",
    "\n",
    "out_folder = '/media/HDD/Self_supervised_BCKUP/Out/'\n",
    "\n",
    "\n",
    "lr = 0.00006\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "num_feat_branch = 60 #46\n",
    "num_feat_simb = 50 #45 \n",
    "\n",
    "feat = 100\n",
    "\n",
    "featref = 45\n",
    "\n",
    "save_weights = 100000\n",
    "\n",
    "#needs to be odd\n",
    "#size of patch-crops fed into the network\n",
    "#patch_size = 21\n",
    "patch_size = 37#27\n",
    "\n",
    "ps_h = int(patch_size/2)\n",
    "\n",
    "#range for offset of o_neg\n",
    "r_low = 1\n",
    "r_high = 25\n",
    "\n",
    "#inference for refiner network\n",
    "upsampling_factor = 1\n",
    "disp_scale = 1\n",
    "downsampling_factor = 1\n",
    "max_disp = 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78a91d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor = torch.cuda.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor\n",
    "cos = torch.nn.CosineSimilarity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4ace01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sine(nn.Module):\n",
    "    def __init__(self, w0: float = 1.0):\n",
    "        super().__init__()\n",
    "        self.w0 = w0\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return torch.sin(self.w0 * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c429a76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SiameseBranch64(nn.Module):\n",
    "    def __init__(self,img_ch=3):\n",
    "        super(SiameseBranch64,self).__init__()\n",
    "\n",
    "        self.Tanh = nn.Tanh() \n",
    "        self.Conv1 = nn.Conv2d(img_ch, num_feat_branch, kernel_size = 3,stride=1,padding = 1,dilation = 1, bias=True)      \n",
    "        self.Conv2 = nn.Conv2d(num_feat_branch, num_feat_branch, kernel_size = 3,stride=1,padding = 1,dilation = 1, bias=True)\n",
    "        self.Conv3 = nn.Conv2d(2*num_feat_branch, num_feat_branch, kernel_size = 3,stride=1,padding = 1,dilation = 1, bias=True)\n",
    "        self.Conv4 = nn.Conv2d(3*num_feat_branch, 60, kernel_size = 3,stride=1,padding = 1,dilation = 1,bias=True)  \n",
    "\n",
    "\n",
    "    def forward(self,x_in):\n",
    "\n",
    "        x1 = self.Conv1(x_in) \n",
    "        x1 = self.Tanh(x1)\n",
    "\n",
    "        x2 = self.Conv2(x1) \n",
    "        x2 = self.Tanh(x2)\n",
    "\n",
    "        d2 = torch.cat((x1,x2),dim=1)\n",
    "\n",
    "        x3 = self.Conv3(d2) \n",
    "        x3 = self.Tanh(x3)\n",
    "\n",
    "        d3 = torch.cat((x1,x2,x3),dim=1)\n",
    "\n",
    "        x4 = self.Conv4(d3)\n",
    "\n",
    "        return x4\n",
    "\n",
    "branch = SiameseBranch64()\n",
    "branch = branch.cuda()\n",
    "\n",
    "#no end-to-end training right now!\n",
    "branch.load_state_dict(torch.load('/media/HDD/Self-Sup-Github/SAda-Net/weights/branch/mb_60f40s_best3800e3277684.000000'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c5ec4b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SimMeasTanh(nn.Module):\n",
    "    def __init__(self,img_ch=2*60):\n",
    "        super(SimMeasTanh,self).__init__()\n",
    "\n",
    "        self.tanh = nn.Tanh() \n",
    "\n",
    "        self.Conv1 = nn.Conv2d(img_ch, num_feat_simb, kernel_size = 3,stride=1,padding = 1,dilation = 1, bias=True)\n",
    "        self.Conv2 = nn.Conv2d(num_feat_simb, num_feat_simb, kernel_size=3,stride=1,padding = 1,dilation = 1, bias=True)\n",
    "        self.Conv3 = nn.Conv2d(2*num_feat_simb, num_feat_simb, kernel_size=3,stride=1,padding = 1,dilation = 1, bias=True)\n",
    "        self.Conv4 = nn.Conv2d(3*num_feat_simb, num_feat_simb, kernel_size=3,stride=1,padding = 1,dilation = 1, bias=True)\n",
    "        self.Conv5 = nn.Conv2d(4*num_feat_simb, 1, kernel_size=3,stride=1,padding = 1,dilation = 1, bias=True)\n",
    "\n",
    "    def forward(self,x_in):\n",
    "\n",
    "        x1 = self.Conv1(x_in) \n",
    "        x1 = self.tanh(x1)\n",
    "\n",
    "        x2 = self.Conv2(x1) \n",
    "        x2 = self.tanh(x2)\n",
    "\n",
    "        d1 = torch.cat((x1,x2),dim=1)\n",
    "\n",
    "\n",
    "        x3 = self.Conv3(d1) \n",
    "        x3 = self.tanh(x3)\n",
    "\n",
    "        d2 = torch.cat((x1,x2,x3),dim=1)\n",
    "\n",
    "        x4 = self.Conv4(d2) \n",
    "        x4 = self.tanh(x4) \n",
    "        d3 = torch.cat((x1,x2,x3,x4),dim=1)\n",
    "        x5 = self.Conv5(d3)\n",
    "\n",
    "        return x5\n",
    "\n",
    "\n",
    "simB = SimMeasTanh()\n",
    "simB = simB.cuda()\n",
    "\n",
    "#no end-to-end training right now!\n",
    "simB.load_state_dict(torch.load('/media/HDD/Self-Sup-Github/SAda-Net/weights/simB/mb_60f40s_best3800e3277684.000000'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b77e4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BranchRefIm(nn.Module):\n",
    "    def __init__(self,img_ch=3):\n",
    "        super(BranchRefIm,self).__init__()\n",
    "\n",
    "        self.Tanh = nn.Tanh() \n",
    "        \n",
    "        self.Sine = Sine()\n",
    "        self.Conv1 = nn.Conv2d(img_ch, feat, kernel_size = 3,stride=1,padding = 1,dilation = 1, bias=True)      \n",
    "        self.Conv2 = nn.Conv2d(feat, feat, kernel_size = 3,stride=1,padding = 1,dilation = 1, bias=True)\n",
    "        self.Conv3 = nn.Conv2d(feat, feat, kernel_size = 3,stride=1,padding = 1,dilation = 1, bias=True)\n",
    "        self.Conv4 = nn.Conv2d(feat, 60, kernel_size = 3,stride=1,padding = 1,dilation = 1,bias=True)  \n",
    "\n",
    "\n",
    "    def forward(self,x_in):\n",
    "\n",
    "        x1 = self.Conv1(x_in) \n",
    "        #x1 = self.Tanh(x1)\n",
    "        x1 = self.Sine(x1)\n",
    "\n",
    "        x2 = self.Conv2(x1) \n",
    "        #x2 = self.Tanh(x2)\n",
    "        x2 = self.Sine(x2)\n",
    "\n",
    "        x3 = self.Conv3(x2) \n",
    "        #x3 = self.Tanh(x3)\n",
    "        x3 = self.Sine(x3)\n",
    "\n",
    "        x4 = self.Conv4(x3)\n",
    "\n",
    "        return x4\n",
    "\n",
    "branchIm = BranchRefIm()\n",
    "branchIm = branchIm.cuda()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b349bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BranchRefDisp(nn.Module):\n",
    "    def __init__(self,img_ch=1):\n",
    "        super(BranchRefDisp,self).__init__()\n",
    "\n",
    "        self.Tanh = nn.Tanh() \n",
    "        self.Sine = Sine()\n",
    "        self.Conv1 = nn.Conv2d(img_ch, feat, kernel_size = 3,stride=1,padding = 1,dilation = 1, bias=True)      \n",
    "        self.Conv2 = nn.Conv2d(feat, feat, kernel_size = 3,stride=1,padding = 1,dilation = 1, bias=True)\n",
    "        self.Conv3 = nn.Conv2d(feat, feat, kernel_size = 3,stride=1,padding = 1,dilation = 1, bias=True)\n",
    "        self.Conv4 = nn.Conv2d(feat, 60, kernel_size = 3,stride=1,padding = 1,dilation = 1,bias=True)  \n",
    "\n",
    "\n",
    "    def forward(self,x_in):\n",
    "\n",
    "        x1 = self.Conv1(x_in) \n",
    "        #x1 = self.Tanh(x1)\n",
    "        x1 = self.Sine(x1)\n",
    "\n",
    "        x2 = self.Conv2(x1) \n",
    "        #x2 = self.Tanh(x2)\n",
    "        x2 = self.Sine(x2)\n",
    "\n",
    "        x3 = self.Conv3(x2) \n",
    "        #x3 = self.Tanh(x3)\n",
    "        x3 = self.Sine(x3)\n",
    "\n",
    "        x4 = self.Conv4(x3)\n",
    "\n",
    "        return x4\n",
    "\n",
    "branchDisp = BranchRefDisp()\n",
    "branchDisp = branchDisp.cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c989563",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RefClass(nn.Module):\n",
    "    def __init__(self,img_ch=120):\n",
    "        super(RefClass,self).__init__()\n",
    "\n",
    "        self.Tanh = nn.Tanh() \n",
    "        self.Sine = Sine()\n",
    "        \n",
    "        self.Conv1 = nn.Conv2d(img_ch, featref, kernel_size = 3,stride=1,padding = 1,dilation = 1, bias=True)      \n",
    "        self.Conv2 = nn.Conv2d(featref, featref, kernel_size = 3,stride=1,padding = 1,dilation = 1, bias=True)\n",
    "        self.Conv3 = nn.Conv2d(featref, featref, kernel_size = 3,stride=1,padding = 1,dilation = 1, bias=True)\n",
    "        \n",
    "        self.Conv4 = nn.Conv2d(featref, 380, kernel_size = 3,stride=1,padding = 1,dilation = 1,bias=True)  \n",
    "        #self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "\n",
    "    def forward(self,x_in):\n",
    "\n",
    "        x1 = self.Conv1(x_in) \n",
    "        #x1 = self.Tanh(x1)\n",
    "        x1 = self.Sine(x1)\n",
    "\n",
    "        x2 = self.Conv2(x1) \n",
    "        #x2 = self.Tanh(x2)\n",
    "        x2 = self.Sine(x2)\n",
    "        \n",
    "        x3 = self.Conv3(x2) \n",
    "        #x3 = self.Tanh(x3)\n",
    "        x3 = self.Sine(x3)\n",
    "\n",
    "        x4 = self.Conv4(x3)\n",
    "        #x5 = self.softmax(x4)\n",
    "\n",
    "        return x4\n",
    "\n",
    "refClass = RefClass()\n",
    "refClass = refClass.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc7a5ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "featrefreg = 100\n",
    "class RefReg(nn.Module):\n",
    "    def __init__(self,img_ch=1):\n",
    "        super(RefReg,self).__init__()\n",
    "\n",
    "        self.Tanh = nn.Tanh() \n",
    "        self.Sine = Sine()\n",
    "        \n",
    "        self.Conv1 = nn.Conv1d(img_ch, featrefreg, kernel_size = 1,stride=1,padding = 0,dilation = 1, bias=True)      \n",
    "        self.Conv2 = nn.Conv1d(featrefreg, featrefreg, kernel_size = 1,stride=1,padding = 0,dilation = 1, bias=True)\n",
    "        self.Conv3 = nn.Conv1d(featrefreg, featrefreg, kernel_size = 1,stride=1,padding = 0,dilation = 1, bias=True)\n",
    "        \n",
    "        self.Conv4 = nn.Conv1d(featrefreg, 1, kernel_size = 1,stride=1,padding = 0,dilation = 1,bias=True)  \n",
    "\n",
    "\n",
    "    def forward(self,x_in):\n",
    "\n",
    "        x1 = self.Conv1(x_in) \n",
    "        #x1 = self.Tanh(x1)\n",
    "        x1 = self.Sine(x1)\n",
    "\n",
    "        x2 = self.Conv2(x1) \n",
    "        #x2 = self.Tanh(x2)\n",
    "        x2 = self.Sine(x2)\n",
    "        \n",
    "        x3 = self.Conv3(x2) \n",
    "        #x3 = self.Tanh(x3)\n",
    "        x3 = self.Sine(x3)\n",
    "\n",
    "        x4 = self.Conv4(x3)\n",
    "        #x5 = self.softmax(x4)\n",
    "        x4 = self.Tanh(x4)\n",
    "        \n",
    "        return x4\n",
    "\n",
    "refreg = RefReg()\n",
    "refreg = refreg.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc4ccdcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr feat branch:  196260\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pytorch_branch_params = sum(p.numel() for p in branch.parameters() if p.requires_grad)\n",
    "print(\"Nr feat branch: \" ,pytorch_branch_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50a6da9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr feat simB:  191001\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pytorch_simb_params = sum(p.numel() for p in simB.parameters() if p.requires_grad)\n",
    "print(\"Nr feat simB: \" ,pytorch_simb_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f43b0ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr feat Im:  237060\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pytorch_im_params = sum(p.numel() for p in branchIm.parameters() if p.requires_grad)\n",
    "print(\"Nr feat Im: \" ,pytorch_im_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f7cc5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr feat Disp:  235260\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pytorch_disp_params = sum(p.numel() for p in branchDisp.parameters() if p.requires_grad)\n",
    "print(\"Nr feat Disp: \" ,pytorch_disp_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d629a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr feat Refine:  239465\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pytorch_refine_params = sum(p.numel() for p in refClass.parameters() if p.requires_grad)\n",
    "print(\"Nr feat Refine: \" ,pytorch_refine_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a5bdef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr feat Regression:  20501\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pytorch_refine_params = sum(p.numel() for p in refreg.parameters() if p.requires_grad)\n",
    "print(\"Nr feat Regression: \" ,pytorch_refine_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b176dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readPFM(file):\n",
    "    file = open(file, 'rb')\n",
    "\n",
    "    color = None\n",
    "    width = None\n",
    "    height = None\n",
    "    scale = None\n",
    "    endian = None\n",
    "\n",
    "    header = file.readline().decode('utf-8').rstrip()\n",
    "    if header == 'PF':\n",
    "        color = True\n",
    "    elif header == 'Pf':\n",
    "        color = False\n",
    "    else:\n",
    "        raise Exception('Not a PFM file.')\n",
    "\n",
    "    dim_match = re.match(r'^(\\d+)\\s(\\d+)\\s$', file.readline().decode('utf-8'))\n",
    "    if dim_match:\n",
    "        width, height = map(int, dim_match.groups())\n",
    "    else:\n",
    "        raise Exception('Malformed PFM header.')\n",
    "\n",
    "    scale = float(file.readline().decode('utf-8').rstrip())\n",
    "    if scale < 0:  # little-endian\n",
    "        endian = '<'\n",
    "        scale = -scale\n",
    "    else:\n",
    "        endian = '>'  # big-endian\n",
    "\n",
    "    data = np.fromfile(file, endian + 'f')\n",
    "    shape = (height, width, 3) if color else (height, width)\n",
    "\n",
    "    data = np.reshape(data, shape)\n",
    "    data = np.flipud(data)\n",
    "    return data, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e6395e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadMB(input_folder):\n",
    "    \n",
    "    left_filelist = glob.glob(input_folder + '/im0.png')\n",
    "    gt_filelist = glob.glob(input_folder + '/disp0GT.pfm')\n",
    "    calib_filelist = glob.glob(input_folder + '/calib.txt')\n",
    "    pred_filelist = glob.glob(input_folder + '/dispPred.pfm')\n",
    "    \n",
    "    right_filelist = glob.glob(input_folder + '/im1.png')\n",
    "    #gt_right_filelist = glob.glob(input_folder + '/disp1GT.pfm')\n",
    "    #pred_right_filelist = glob.glob(input_folder + '/dispPredR.pfm')\n",
    "    \n",
    "    left_filelist = sorted(left_filelist)\n",
    "    right_filelist = sorted(right_filelist)\n",
    "    gt_filelist = sorted(gt_filelist)\n",
    "    calib_filelist = sorted(calib_filelist)\n",
    "    pred_filelist = sorted(pred_filelist)\n",
    "    \n",
    "    right_filelist = sorted(right_filelist)\n",
    "   # gt_right_filelist = sorted(gt_right_filelist)\n",
    "    #pred_right_filelist = sorted(pred_right_filelist)\n",
    "    \n",
    "    \n",
    "    left_list = []\n",
    "    gt_list = []\n",
    "    maxdisp_list = []\n",
    "    s_name_list = []\n",
    "    pred_list = []\n",
    "    \n",
    "    right_list = []\n",
    "    #predR_list = []\n",
    "    #gtR_list = []\n",
    "    \n",
    "    for i in range(0,len(left_filelist)):\n",
    "        \n",
    "        cur_left = cv2.imread(left_filelist[i])\n",
    "        cur_gt,_ = readPFM(gt_filelist[i])\n",
    "        \n",
    "        cur_gt[np.isnan(cur_gt)] = 0\n",
    "        cur_gt[np.isinf(cur_gt)] = 0\n",
    "        \n",
    "        cur_pred, _ = readPFM(pred_filelist[i])\n",
    "        pred_list.append(cur_pred)        \n",
    "        \n",
    "        cur_right = cv2.imread(right_filelist[i])        \n",
    "        #cur_gtR, _ = readPFM(gt_right_filelist[i])\n",
    "        #predR, _ = readPFM(pred_right_filelist[i])\n",
    "        \n",
    "       # cur_gtR[np.isnan(cur_gtR)] = 0\n",
    "        #cur_gtR[np.isinf(cur_gtR)] = 0\n",
    "        \n",
    "        left_list.append(cur_left)\n",
    "        gt_list.append(cur_gt)\n",
    "        \n",
    "        #just one list? should work in theory => try it!\n",
    "       # left_list.append(cur_right)\n",
    "        #just bc lazy\n",
    "        right_list.append(cur_right)\n",
    "        \n",
    "        #gt_list.append(cur_gtR)\n",
    "       # pred_list.append(predR)\n",
    "        \n",
    "        s_name = left_filelist[i].split('/')[-2]\n",
    "       # s_name_list.append(s_name)\n",
    "        s_name_list.append(s_name)\n",
    "        \n",
    "        f = open(calib_filelist[i],'r')\n",
    "        calib = f.read()\n",
    "        max_disp = int(calib.split('\\n')[6].split(\"=\")[1])\n",
    "        \n",
    "        \n",
    "        maxdisp_list.append(max_disp)\n",
    "                \n",
    "        \n",
    "    return left_list, right_list, gt_list, maxdisp_list, s_name_list, pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d71c1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "left_list, right_list, gt_list,max_disp_list, s_name_list, pred_list = loadMB(input_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "315cead9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cross_entropy = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f032b0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBatch(): #gt_cons_cpy\n",
    "    \n",
    "    batch_xl = np.zeros((batch_size,3,patch_size,patch_size))\n",
    "    \n",
    "    batch_gt = np.zeros((batch_size,1, patch_size,patch_size)) \n",
    "    \n",
    "    label_gt = np.zeros((batch_size,380, patch_size,patch_size))\n",
    "    label_gt_int = np.zeros((batch_size,1, patch_size,patch_size))\n",
    "    \n",
    "    batch_pred = np.zeros((batch_size,1, patch_size,patch_size))\n",
    "    \n",
    "    \n",
    "    for el in range(batch_size):\n",
    "        \n",
    "        if(el % 10 == 0):\n",
    "            \n",
    "            ridx = np.random.randint(0,len(left_list),1)\n",
    "            left_im = left_list[ridx[0]]\n",
    "            gt_im = gt_list[ridx[0]]\n",
    "            pred_im = pred_list[ridx[0]]\n",
    "        \n",
    "        \n",
    "        h,w,c = left_im.shape\n",
    "        r_h = 0\n",
    "        r_w = 0\n",
    "        d = 0\n",
    "        \n",
    "#        print('Draw for random position')\n",
    "        #also check height! should not draw corner pixels!!\n",
    "        while True:\n",
    "            \n",
    "            r_h = random.sample(range(ps_h,h-(ps_h+1)), 1)\n",
    "            r_w = random.sample(range(ps_h,w-(ps_h+1)),1)   \n",
    "            \n",
    "            if(not np.isnan(gt_im[r_h,r_w])):\n",
    "                d = int(np.round(gt_im[r_h,r_w]))\n",
    "                if((r_w[0]-ps_h-d-1) >= 0):\n",
    "                     if((r_w[0]+(ps_h+1)-d+1) <= w):\n",
    "                        break\n",
    "        \n",
    "        d = int(np.round(gt_im[r_h,r_w]))\n",
    "                \n",
    "        cur_left = left_im[r_h[0]-ps_h:r_h[0]+(ps_h+1), r_w[0]-ps_h:r_w[0]+(ps_h+1),:]\n",
    "        \n",
    "        cur_gt = gt_im[r_h[0]-ps_h:r_h[0]+(ps_h+1), r_w[0]-ps_h:r_w[0]+(ps_h+1)]\n",
    "        cur_gt[np.isnan(cur_gt)] = 0.0\n",
    "        cur_gt = np.expand_dims(cur_gt,axis=2)\n",
    "        \n",
    "        cur_pred = pred_im[r_h[0]-ps_h:r_h[0]+(ps_h+1), r_w[0]-ps_h:r_w[0]+(ps_h+1)]\n",
    "        cur_pred = np.expand_dims(cur_pred,axis=2)\n",
    "        \n",
    "        h,w,c = cur_gt.shape\n",
    "        \n",
    "        for h_ in range(h):\n",
    "            for w_ in range(w):\n",
    "                \n",
    "                #print(cur_gtT[h_,w_])\n",
    "                enc_pos = int(cur_gt[h_,w_,:])\n",
    "                label_gt[el,enc_pos,h_,w_] = 1\n",
    "                \n",
    "                label_gt_int[el,:,h_,w_] = enc_pos\n",
    "               \n",
    "            \n",
    "        #cur_gtT = torch.tensor(cur_gt)\n",
    "        \n",
    "        batch_xl[el,:,:,:] =  np.transpose(cur_left, (2,0,1)).astype(np.uint8)\n",
    "        batch_gt[el,:,:,:] =  np.transpose(cur_gt, (2,0,1)).astype(np.uint8)\n",
    "        \n",
    "        batch_pred[el,:,:,:] =  np.transpose(cur_pred, (2,0,1)).astype(np.uint8)\n",
    "        \n",
    "        \n",
    "    return batch_xl, batch_gt, batch_pred, label_gt, label_gt_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0bb7666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcEPE(disp, gt_fn):\n",
    "    \n",
    "    gt = gt_fn\n",
    "\n",
    "    gt[np.where(gt == np.inf)] = -100\n",
    "    #for loadmb\n",
    "    gt[np.where(gt == 0)] = -100\n",
    "    \n",
    "    mask = gt > 0\n",
    "\n",
    "    disp = disp[mask]\n",
    "    gt = gt[mask]        \n",
    "\n",
    "    nr_px = len(gt)\n",
    "\n",
    "\n",
    "    abs_error_im = np.abs(disp - gt)\n",
    "\n",
    "    five_pe = (float(np.count_nonzero(abs_error_im >= 5.0) ) / nr_px) * 100.0  \n",
    "    four_pe = (float(np.count_nonzero(abs_error_im >= 4.0) ) / nr_px) * 100.0  \n",
    "    three_pe = (float(np.count_nonzero(abs_error_im >= 3.0) ) / nr_px) * 100.0  \n",
    "    two_pe = (float(np.count_nonzero(abs_error_im >= 2.0) ) / nr_px) * 100.0        \n",
    "    one_pe = (float(np.count_nonzero(abs_error_im >= 1.0) ) / nr_px) * 100.0        \n",
    "    pf_pe = (float(np.count_nonzero(abs_error_im >= 0.5) ) / nr_px) * 100.0  \n",
    "        \n",
    "    return five_pe, four_pe, three_pe, two_pe, one_pe, pf_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e38f2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writePFM(file, image, scale=1):\n",
    "    file = open(file, 'wb')\n",
    "\n",
    "    color = None\n",
    "\n",
    "    image = np.flipud(image)\n",
    "\n",
    "    if len(image.shape) == 3 and image.shape[2] == 3:  # color image\n",
    "        color = True\n",
    "    elif len(image.shape) == 2 or len(image.shape) == 3 and image.shape[2] == 1:  # greyscale\n",
    "        color = False\n",
    "    else:\n",
    "        raise Exception('Image must have H x W x 3, H x W x 1 or H x W dimensions.')\n",
    "\n",
    "    file.write('PF\\n'.encode() if color else 'Pf\\n'.encode())\n",
    "    file.write('%d %d\\n'.encode() % (image.shape[1], image.shape[0]))\n",
    "\n",
    "    endian = image.dtype.byteorder\n",
    "\n",
    "    scale = -scale\n",
    "\n",
    "    file.write('%f\\n'.encode() % scale)\n",
    "    image.tofile(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d638d582",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Eval(epoch):\n",
    "    \n",
    "    avg_4_pe = 0.0\n",
    "    avg_2_pe = 0.0\n",
    "    avg_1_pe = 0.0\n",
    "    avg_pf_pe = 0.0\n",
    "\n",
    "    for sample in range(len(left_list)):\n",
    "        \n",
    "        left = left_list[sample]\n",
    "        pred = pred_list[sample]\n",
    "\n",
    "        left = np.transpose(left, (2,0,1)).astype(np.uint8)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "\n",
    "            xlT = Variable(Tensor(left)).unsqueeze(0)\n",
    "            predT = Variable(Tensor(pred.copy())).unsqueeze(0).unsqueeze(0)\n",
    "            \n",
    "            #xlT = (xlT-torch.mean(xlT))/torch.std(xlT)\n",
    "            #predT = (predT-torch.mean(predT))/torch.std(predT)\n",
    "\n",
    "            outXlT = branchIm(xlT)\n",
    "            outDispT = branchDisp(predT)\n",
    "\n",
    "            xlDispConcat = torch.cat((outXlT,outDispT),dim=1).squeeze(2)\n",
    "\n",
    "            refDispT = refClass(xlDispConcat)\n",
    "\n",
    "            pred = torch.argmax(refDispT, axis = 1)\n",
    "\n",
    "            five_pe, four_pe, three_pe, two_pe, one_pe, pf_pe = calcEPE(pred.squeeze().cpu().data.numpy(), gt_list[sample])\n",
    "\n",
    "            #print(\"2-PE: {}\".format(two_pe))\n",
    "            avg_4_pe = avg_4_pe + four_pe\n",
    "            avg_2_pe = avg_2_pe + two_pe\n",
    "            avg_1_pe = avg_1_pe + one_pe\n",
    "            avg_pf_pe = avg_pf_pe + pf_pe\n",
    "\n",
    "            writePFM('/media/HDD/Self-Sup-Github/SAda-Net/OUTNEW/%s_%06d_e%06f.pfm' %(s_name_list[sample], epoch,two_pe), pred.squeeze().cpu().data.numpy().astype(np.float32))\n",
    "\n",
    "        \n",
    "    avg_4_pe = avg_4_pe / len(left_list)\n",
    "    avg_2_pe = avg_2_pe / len(left_list)\n",
    "    avg_1_pe = avg_1_pe / len(left_list)\n",
    "    avg_pf_pe = avg_pf_pe / len(left_list)\n",
    "    \n",
    "    print(\"Avg. 4-PE: {}\".format(avg_4_pe))\n",
    "    print(\"Avg. 2-PE: {}\".format(avg_2_pe))\n",
    "    print(\"Avg. 1-PE: {}\".format(avg_1_pe))\n",
    "    print(\"Avg. 0.5-PE: {}\".format(avg_pf_pe))\n",
    "    \n",
    "    return avg_2_pe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e819afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#even further improve this by using pytorch!\n",
    "def LR_Check(first_output, second_output, dataset):    \n",
    "    \n",
    "    h,w = first_output.shape\n",
    "        \n",
    "    line = np.array(range(0, w))\n",
    "    idx_arr = np.matlib.repmat(line,h,1)    \n",
    "    \n",
    "    dif = idx_arr - first_output\n",
    "    \n",
    "    first_output[np.where(dif <= 0)] = 0\n",
    "    \n",
    "    first_output = first_output.astype(int)\n",
    "    second_output = second_output.astype(int)\n",
    "    dif = dif.astype(int)\n",
    "    \n",
    "    second_arr_reordered = np.array(list(map(lambda x, y: y[x], dif, second_output)))\n",
    "    \n",
    "    dif_LR = np.abs(second_arr_reordered - first_output)\n",
    "    first_output[np.where(dif_LR >= 1.1)] = 0\n",
    "    \n",
    "    if(dataset == 'MB'):\n",
    "        first_output[np.where(first_output <= 15.0)] = 0\n",
    "        \n",
    "    \n",
    "    first_output = first_output.astype(np.float32)\n",
    "    first_output[np.where(first_output == 0.0)] = np.nan\n",
    "    \n",
    "        \n",
    "    return first_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2bb20449",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1d970fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%cython -a\n",
    "import numpy as np\n",
    "import cython\n",
    "#@cython.boundscheck(False)\n",
    "#@cython.nonecheck(False)\n",
    "@cython.wraparound(False)\n",
    "cpdef float[:, :] FillIncons(unsigned char[:, :] mask, float[:, :] disp):\n",
    "\n",
    "    cpdef int curnan, curnanh, curnanw,curw, w, h ,left, right, above, under, r_above, l_above, r_under, l_under\n",
    "    cpdef float fill  \n",
    "    cpdef int max_search\n",
    "    \n",
    "    max_search = 30\n",
    "    \n",
    "    w = mask.shape[1]\n",
    "    h = mask.shape[0] \n",
    "    \n",
    "    #BG\n",
    "    idc = np.argwhere(np.isnan(disp))    \n",
    "    for curnan in range(len(idc)):\n",
    "        \n",
    "        curnanh = idc[curnan][0]\n",
    "        curnanw = idc[curnan][1]        \n",
    "        if(mask[curnanh,curnanw] == 0):\n",
    "            \n",
    "            #whole scanline is nan => disp is 0\n",
    "            if(all(np.isnan(disp[curnanh,:]))):\n",
    "                #hole line set to 0!\n",
    "                disp[curnanh,:] = 0.0\n",
    "                \n",
    "            #all px to the left are NaN\n",
    "            if(all(np.isnan(disp[curnanh,0:curnanw]))):\n",
    "                #go to the right\n",
    "                curw = curnanw\n",
    "                fill = 0\n",
    "                while(np.isnan(disp[curnanh,curw]) and mask[curnanh,curnanw] == 0):\n",
    "                    curw = curw +1\n",
    "                    fill = disp[curnanh,curw]\n",
    "                disp[curnanh,curnanw] = fill\n",
    "                \n",
    "            #else go left\n",
    "            else:\n",
    "                curw = curnanw\n",
    "                fill = 0\n",
    "                while(np.isnan(disp[curnanh,curw]) and mask[curnanh,curnanw] == 0):\n",
    "                    curw = curw -1\n",
    "                    fill = disp[curnanh,curw]\n",
    "                disp[curnanh,curnanw] = fill \n",
    "    \n",
    "    #FG\n",
    "    idcFG = np.argwhere(np.isnan(disp))\n",
    "    for curnan in range(len(idcFG)):\n",
    "        \n",
    "        curnanh = idcFG[curnan][0]\n",
    "        curnanw = idcFG[curnan][1]\n",
    "      \n",
    "        left = 0\n",
    "        right = 0\n",
    "        above = 0\n",
    "        under = 0\n",
    "\n",
    "        r_above = 0\n",
    "        l_above = 0\n",
    "        r_under = 0\n",
    "        l_under = 0      \n",
    "        \n",
    "        \n",
    "        if(curnanw == 0):\n",
    "            left = 0\n",
    "        else:\n",
    "            left = int(disp[curnanh,curnanw-1])\n",
    "            \n",
    "        counter = 0                                    \n",
    "        while(np.isnan(disp[curnanh,curnanw+counter])):\n",
    "            counter = counter +1                       \n",
    "            if((curnanw+counter) >= w or counter >= max_search):\n",
    "                right = 0\n",
    "                break\n",
    "            right = int(disp[curnanh,curnanw+counter])\n",
    "        \n",
    "        counter = 0                                    \n",
    "        while(np.isnan(disp[curnanh+counter,curnanw])):\n",
    "            counter = counter +1                       \n",
    "            if((curnanh+counter) >= h or counter >= max_search):\n",
    "                above = 0\n",
    "                break       \n",
    "            above = int(disp[curnanh+counter,curnanw])\n",
    "             \n",
    "        if(curnanh == 0):\n",
    "            under = 0\n",
    "        else:\n",
    "            under = int(disp[curnanh-1,curnanw])\n",
    "        \n",
    "        \n",
    "        counter = 0                                    \n",
    "        while(np.isnan(disp[curnanh+counter,curnanw+counter])):\n",
    "            counter = counter +1\n",
    "            if((curnanh+counter) >= h or counter >= max_search):\n",
    "                r_above = 0\n",
    "                break\n",
    "            if((curnanw+counter) >= w):\n",
    "                r_above = 0\n",
    "                break                        \n",
    "            r_above = int(disp[curnanh+counter,curnanw+counter])     \n",
    "        \n",
    "        if(curnanh == 0 or curnanw == 0):\n",
    "            l_under = 0\n",
    "        else:\n",
    "            l_under = int(disp[curnanh-1,curnanw-1])\n",
    "             \n",
    "        \n",
    "        counter = 0      \n",
    "        while(np.isnan(disp[curnanh+counter,curnanw-counter])):\n",
    "            counter = counter +1\n",
    "            if((curnanh+counter) >= h):\n",
    "                l_above = 0\n",
    "                break\n",
    "            if((curnanw-counter) <= 0 or counter >= max_search):\n",
    "                l_above = 0\n",
    "                break\n",
    "            l_above = int(disp[curnanh+counter,curnanw-counter])\n",
    "\n",
    "        if(curnanh == 0 or curnanw >= w-1):\n",
    "            r_under = 0\n",
    "        else:\n",
    "            r_under = int(disp[curnanh-1,curnanw+1])\n",
    "         \n",
    "        fill = np.median([left,right,above,under,r_above,l_above,r_under,l_under])\n",
    "        disp[curnanh,curnanw] = fill\n",
    "\n",
    "    return disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7c3aad67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EvalLR(epoch):\n",
    "    \n",
    "    avg_4_pe = 0.0\n",
    "    avg_2_pe = 0.0\n",
    "    avg_1_pe = 0.0\n",
    "    avg_pf_pe = 0.0\n",
    "\n",
    "    predR_list = glob.glob('/media/HDD/Self-Sup-Github/SAda-Net/TrainingRef/*/dispPredR.pfm')\n",
    "    right_list = glob.glob('/media/HDD/Self-Sup-Github/SAda-Net/TrainingRef/*/im1.png')\n",
    "    \n",
    "    right_list = sorted(right_list)\n",
    "    predR_list = sorted(predR_list)\n",
    "    \n",
    "    for sample in range(len(left_list)):\n",
    "        \n",
    "        left = left_list[sample]\n",
    "        pred = pred_list[sample]\n",
    "\n",
    "        left = np.transpose(left, (2,0,1)).astype(np.uint8)\n",
    "        \n",
    "        right_f = right_list[sample]\n",
    "        right = cv2.imread(right_f)\n",
    "        predR_f = predR_list[sample]\n",
    "        \n",
    "        right = np.transpose(right, (2,0,1)).astype(np.uint8)\n",
    "        \n",
    "        predR, _ = readPFM(predR_f)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "\n",
    "            xlT = Variable(Tensor(left)).unsqueeze(0)\n",
    "            predT = Variable(Tensor(pred.copy())).unsqueeze(0).unsqueeze(0)\n",
    "            \n",
    "            #xlT = (xlT-torch.mean(xlT))/torch.std(xlT)\n",
    "            #predT = (predT-torch.mean(predT))/torch.std(predT)\n",
    "\n",
    "            outXlT = branchIm(xlT)\n",
    "            outDispT = branchDisp(predT)\n",
    "\n",
    "            xlDispConcat = torch.cat((outXlT,outDispT),dim=1).squeeze(2)\n",
    "\n",
    "            refDispT = refClass(xlDispConcat)\n",
    "\n",
    "            pred = torch.argmax(refDispT, axis = 1)\n",
    "                        \n",
    "            #five_pe, four_pe, three_pe, two_pe, one_pe, pf_pe = calcEPE(pred.squeeze().cpu().data.numpy(), gt_list[sample])\n",
    "\n",
    "            #print(\"2-PE: {}\".format(two_pe))\n",
    "            #avg_4_pe = avg_4_pe + four_pe\n",
    "            #avg_2_pe = avg_2_pe + two_pe\n",
    "            #avg_1_pe = avg_1_pe + one_pe\n",
    "            #avg_pf_pe = avg_pf_pe + pf_pe\n",
    "\n",
    "\n",
    "            ####################R#####################\n",
    "            xrT = Variable(Tensor(right)).unsqueeze(0)\n",
    "            predRT = Variable(Tensor(predR.copy())).unsqueeze(0).unsqueeze(0)\n",
    "            \n",
    "            outXrT = branchIm(xrT)\n",
    "            outDispRT = branchDisp(predRT)\n",
    "\n",
    "            xrDispConcat = torch.cat((outXrT,outDispRT),dim=1).squeeze(2)\n",
    "\n",
    "            refDispRT = refClass(xrDispConcat)\n",
    "\n",
    "            predR = torch.argmax(refDispRT, axis = 1)\n",
    "            \n",
    "            \n",
    "            ###########################\n",
    "            \n",
    "            disp_s = LR_Check(pred.squeeze().cpu().data.numpy(), predR.squeeze().cpu().data.numpy(), 'MB')\n",
    "\n",
    "            disp_s_arr = np.array(disp_s)\n",
    "            im_disp = Image.fromarray(disp_s_arr) \n",
    "            im_disp = np.dstack((im_disp, im_disp, im_disp)).astype(np.uint8)    \n",
    "\n",
    "            h,w = disp_s.shape\n",
    "\n",
    "            shifted = cv2.pyrMeanShiftFiltering(im_disp, 7, 7)\n",
    "\n",
    "            gray = cv2.cvtColor(shifted, cv2.COLOR_BGR2GRAY)\n",
    "            thresh = cv2.threshold(gray, 0, 1,\n",
    "                cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "            disp_filled  = FillIncons(thresh, disp_s_arr)\n",
    "            \n",
    "            disp_filled = np.array(disp_filled)      \n",
    "            \n",
    "            five_pe, four_pe, three_pe, two_pe, one_pe, pf_pe = calcEPE(disp_filled, gt_list[sample])\n",
    "\n",
    "            #print(\"2-PE: {}\".format(two_pe))\n",
    "            avg_4_pe = avg_4_pe + four_pe\n",
    "            avg_2_pe = avg_2_pe + two_pe\n",
    "            avg_1_pe = avg_1_pe + one_pe\n",
    "            avg_pf_pe = avg_pf_pe + pf_pe\n",
    "            \n",
    "            writePFM('/media/HDD/Self-Sup-Github/SAda-Net/OUTNEW/%s_%06d_e%06f_filled.pfm' %(s_name_list[sample], epoch,two_pe),disp_filled)\n",
    "            writePFM('/media/HDD/Self-Sup-Github/SAda-Net/OUTNEW/%s_%06d_e%06f.pfm' %(s_name_list[sample], epoch,two_pe), pred.squeeze().cpu().data.numpy().astype(np.float32))\n",
    "            writePFM('/media/HDD/Self-Sup-Github/SAda-Net/OUTNEW/%s_%06d_e%06fR.pfm' %(s_name_list[sample], epoch,two_pe), predR.squeeze().cpu().data.numpy().astype(np.float32))\n",
    "            \n",
    "            \n",
    "    \n",
    "    avg_4_pe = avg_4_pe / len(left_list)\n",
    "    avg_2_pe = avg_2_pe / len(left_list)\n",
    "    avg_1_pe = avg_1_pe / len(left_list)\n",
    "    avg_pf_pe = avg_pf_pe / len(left_list)\n",
    "    \n",
    "    print(\"Avg. 4-PE: {}\".format(avg_4_pe))\n",
    "    print(\"Avg. 2-PE: {}\".format(avg_2_pe))\n",
    "    print(\"Avg. 1-PE: {}\".format(avg_1_pe))\n",
    "    print(\"Avg. 0.5-PE: {}\".format(avg_pf_pe))\n",
    "    \n",
    "    return avg_2_pe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30b3befa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#branchIm.load_state_dict(torch.load('/media/HDD/Self-Sup-Github/SAda-Net/weights/Trained/branchDisp/mb_best'))\n",
    "#branchDisp.load_state_dict(torch.load('/media/HDD/Self-Sup-Github/SAda-Net/weights/Trained/branchIm/mb_best'))\n",
    "#refClass.load_state_dict(torch.load('/media/HDD/Self-Sup-Github/SAda-Net/weights/Trained/refClass/mb_best'))\n",
    "\n",
    "\n",
    "branchIm.load_state_dict(torch.load('/media/HDD/Self-Sup-Github/SAda-Net/weights/Trained/branchIm/mb_60f40s_best395000e7.798881'))\n",
    "branchDisp.load_state_dict(torch.load('/media/HDD/Self-Sup-Github/SAda-Net/weights/Trained/branchDisp/mb_60f40s_best395000e7.798881'))\n",
    "refClass.load_state_dict(torch.load('/media/HDD/Self-Sup-Github/SAda-Net/weights/Trained/refClass/mb_60f40s_best395000e7.798881'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28a8fcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#avg_2_pe = EvalLR(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af693bc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#two_pe = Eval(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b17568",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#EvalLR(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a09f076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a257ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_own(gt_i, probs):\n",
    "        \n",
    "    gt = torch.exp(-0.5 * torch.abs(self.labels - gt_i) ** 2 / 2) / 2\n",
    "\n",
    "    -(gt * torch.log(probs + 1e-10))\n",
    "\n",
    "    ce = torch.mean(ce, dim=2)\n",
    "    ce = torch.mean(ce, dim=0)\n",
    "    classification_loss = torch.sum(ce)\n",
    "    \n",
    "    return classification_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc350a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd82bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(branchIm.parameters()) +  list(branchDisp.parameters()) + list(refClass.parameters())\n",
    "\n",
    "optimizer_G = optim.Adam(params, lr)\n",
    "\n",
    "#optimizer_G = optim.SGD(params, 0.1, momentum=0.9)\n",
    "best_err = 10000000000\n",
    "\n",
    "early_stopping_count = 0\n",
    "\n",
    "i = 0\n",
    "\n",
    "batch_xl, batch_gt, batch_pred, label_gt, label_gt_int = getBatch()\n",
    "loss_list = []\n",
    "\n",
    "avg_2_pe = 10000\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    #do not train now!\n",
    "    break\n",
    "    \n",
    "    epoch_loss = 0.0\n",
    "    optimizer_G.zero_grad()\n",
    "    \n",
    "\n",
    "    batch_xlT = Variable(Tensor(batch_xl))\n",
    "    batch_predT = Variable(Tensor(batch_pred))\n",
    "    label_gtT = Variable(LongTensor(label_gt_int))\n",
    "    label_gtF = Variable(Tensor(label_gt_int))\n",
    "    \n",
    "    #batch_xlT = (batch_xlT-torch.mean(batch_xlT))/torch.std(batch_xlT)\n",
    "    #batch_predT = (batch_predT-torch.mean(batch_predT))/torch.std(batch_predT)\n",
    "\n",
    "    outXlT = branchIm(batch_xlT)\n",
    "    outDispT = branchDisp(batch_predT)\n",
    "\n",
    "    xlDispConcat = torch.cat((outXlT,outDispT),dim=1).squeeze(2)\n",
    "\n",
    "    refDispT = refClass(xlDispConcat)\n",
    "\n",
    "    pred = torch.argmax(refDispT, axis = 1)\n",
    "    ce_loss = cross_entropy(refDispT, label_gtT.squeeze())\n",
    "        \n",
    "    #classification_loss = ce_loss * torch.normal(torch.mean(label_gtF), torch.std(label_gtF)).mean()\n",
    "    \n",
    "    #classification_loss = torch.sum(ce)\n",
    "    \n",
    "    ce_loss.backward()\n",
    "    \n",
    "    loss_list.append(ce_loss.cpu().data.numpy())\n",
    "    \n",
    "    \n",
    "    #loss_list.append(ce_loss.cpu().data.numpy())\n",
    "    #ce_loss.backward()\n",
    "    optimizer_G.step()\n",
    "    \n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #if(i % 100 == 0):\n",
    "    batch_xl, batch_gt, batch_pred, label_gt, label_gt_int = getBatch()\n",
    "        \n",
    "        \n",
    "    if(i % 1000 == 0):\n",
    "        \n",
    "        #batch_xl, batch_gt, batch_pred, label_gt, label_gt_int = getBatch()\n",
    "        \n",
    "        print(ce_loss.cpu().data.numpy())\n",
    "        \n",
    "        two_pe = Eval(i)\n",
    "        if(two_pe < avg_2_pe):\n",
    "            print(\"Improved: {}\".format(two_pe))\n",
    "            avg_2_pe = two_pe\n",
    "            torch.save(branchIm.state_dict(), save_folder_branchim + model_name + '_best%04i' %(i) + 'e%04f' %(avg_2_pe)) \n",
    "            torch.save(branchDisp.state_dict(), save_folder_branchdisp + model_name + '_best%04i' %(i) + 'e%04f' %(avg_2_pe)) \n",
    "            torch.save(refClass.state_dict(), save_folder_refine + model_name + '_best%04i' %(i) + 'e%04f' %(avg_2_pe)) \n",
    "            early_stopping_count = 0\n",
    "            \n",
    "        else:\n",
    "            print(\"Did not improve\")\n",
    "            early_stopping_count = early_stopping_count + 1\n",
    "        if(early_stopping_count >= 20):\n",
    "            print(\"Stop Training\")\n",
    "            break\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d330f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadRefineDisp():\n",
    "    \n",
    "    disp_ref_list_f = glob.glob('/media/HDD/Self-Sup-Github/SAda-Net/OUTNEW/BestOwn/*.pfm')\n",
    "    disp_ref_list_f = sorted(disp_ref_list_f)\n",
    "    \n",
    "    disp_ref_list = []\n",
    "    \n",
    "    for i in range(len(disp_ref_list_f)):\n",
    "        \n",
    "        cur_disp_ref, _ = readPFM(disp_ref_list_f[i])\n",
    "        disp_ref_list.append(cur_disp_ref)\n",
    "        \n",
    "    \n",
    "    return disp_ref_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1372fdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_binary_kernel(window_size: Tuple[int, int]) -> torch.Tensor:\n",
    "    r\"\"\"Creates a binary kernel to extract the patches. If the window size\n",
    "    is HxW will create a (H*W)xHxW kernel.\n",
    "    \"\"\"\n",
    "    window_range: int = window_size[0] * window_size[1]\n",
    "    kernel: torch.Tensor = torch.zeros(window_range, window_range)\n",
    "    for i in range(window_range):\n",
    "        kernel[i, i] += 1.0\n",
    "    return kernel.view(window_range, 1, window_size[0], window_size[1])\n",
    "\n",
    "\n",
    "def _compute_zero_padding(kernel_size: Tuple[int, int]) -> Tuple[int, int]:\n",
    "    r\"\"\"Utility function that computes zero padding tuple.\"\"\"\n",
    "    computed: Tuple[int, ...] = tuple([(k - 1) // 2 for k in kernel_size])\n",
    "    return computed[0], computed[1]\n",
    "\n",
    "\n",
    "class MedianBlur(nn.Module):\n",
    "    r\"\"\"Blurs an image using the median filter.\n",
    "\n",
    "    Args:\n",
    "        kernel_size (Tuple[int, int]): the blurring kernel size.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: the blurred input tensor.\n",
    "\n",
    "    Shape:\n",
    "        - Input: :math:`(B, C, H, W)`\n",
    "        - Output: :math:`(B, C, H, W)`\n",
    "\n",
    "    Example:\n",
    "        >>> input = torch.rand(2, 4, 5, 7)\n",
    "        >>> blur = kornia.filters.MedianBlur((3, 3))\n",
    "        >>> output = blur(input)  # 2x4x5x7\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size: Tuple[int, int]) -> None:\n",
    "        super(MedianBlur, self).__init__()\n",
    "        self.kernel: torch.Tensor = _compute_binary_kernel(kernel_size)\n",
    "        self.padding: Tuple[int, int] = _compute_zero_padding(kernel_size)\n",
    "\n",
    "    def forward(self, input: torch.Tensor):  # type: ignore\n",
    "        if not torch.is_tensor(input):\n",
    "            raise TypeError(\"Input type is not a torch.Tensor. Got {}\"\n",
    "                            .format(type(input)))\n",
    "        if not len(input.shape) == 4:\n",
    "            raise ValueError(\"Invalid input shape, we expect BxCxHxW. Got: {}\"\n",
    "                             .format(input.shape))\n",
    "        # prepare kernel\n",
    "        b, c, h, w = input.shape\n",
    "        tmp_kernel: torch.Tensor = self.kernel.to(input.device).to(input.dtype)\n",
    "        kernel: torch.Tensor = tmp_kernel.repeat(c, 1, 1, 1)\n",
    "\n",
    "        # map the local window to single vector\n",
    "        features: torch.Tensor = F.conv2d(\n",
    "            input, kernel, padding=self.padding, stride=1, groups=c)\n",
    "        features = features.view(b, c, -1, h, w)  # BxCx(K_h * K_w)xHxW\n",
    "\n",
    "        # compute the median along the feature axis\n",
    "        median: torch.Tensor = torch.median(features, dim=2)[0]\n",
    "        return median\n",
    "\n",
    "# functiona api\n",
    "def median_blur(input: torch.Tensor,\n",
    "                kernel_size: Tuple[int, int]) -> torch.Tensor:\n",
    "    r\"\"\"Blurs an image using the median filter.\n",
    "\n",
    "    See :class:`~kornia.filters.MedianBlur` for details.\n",
    "    \"\"\"\n",
    "    return MedianBlur(kernel_size)(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab32719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EvalReg(epoch):\n",
    "    \n",
    "    avg_4_pe = 0.0\n",
    "    avg_2_pe = 0.0\n",
    "    avg_1_pe = 0.0\n",
    "    avg_pf_pe = 0.0\n",
    "\n",
    "    for sample in range(len(left_list)):\n",
    "        \n",
    "        pred = disp_ref_list[sample]\n",
    "\n",
    "        \n",
    "        with torch.no_grad():\n",
    "\n",
    "            predFullT = Variable(Tensor(pred.copy()))\n",
    "            h,w = predFullT.shape\n",
    "            outFullT = refreg(predFullT.unsqueeze(0))\n",
    "            #outFullT = torch.reshape(outFullT, (h,w))\n",
    "            \n",
    "            pred_out = pred + outFullT.squeeze().cpu().data.numpy()\n",
    "            \n",
    "            five_pe, four_pe, three_pe, two_pe, one_pe, pf_pe = calcEPE(pred_out, gt_list[sample])\n",
    "\n",
    "            avg_4_pe = avg_4_pe + four_pe\n",
    "            avg_2_pe = avg_2_pe + two_pe\n",
    "            avg_1_pe = avg_1_pe + one_pe\n",
    "            avg_pf_pe = avg_pf_pe + pf_pe\n",
    "\n",
    "            #writePFM('/media/HDD/Self-Sup-Github/SAda-Net/OUTNEW/%s_%06d_e%06f.pfm' %(s_name_list[sample], epoch,two_pe), pred_out)\n",
    "\n",
    "        \n",
    "    avg_4_pe = avg_4_pe / len(left_list)\n",
    "    avg_2_pe = avg_2_pe / len(left_list)\n",
    "    avg_1_pe = avg_1_pe / len(left_list)\n",
    "    avg_pf_pe = avg_pf_pe / len(left_list)\n",
    "    \n",
    "   # print(\"Avg. 4-PE: {}\".format(avg_4_pe))\n",
    "    #print(\"Avg. 2-PE: {}\".format(avg_2_pe))\n",
    "    #print(\"Avg. 1-PE: {}\".format(avg_1_pe))\n",
    "    print(\"Avg. 0.5-PE: {}\".format(avg_pf_pe))\n",
    "    \n",
    "    #0.5 PE should improve most\n",
    "    return avg_pf_pe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063f89fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RegLoss(gt_batch, ds_batch, pred_batch):\n",
    "    \n",
    "    ds = gt_batch - ds_batch\n",
    "    loss = torch.abs(pred_batch - ds)\n",
    "    torch.where(loss < -1.0, loss, 0.0)\n",
    "    torch.where(loss > 1.0, loss, 0.0)\n",
    "    \n",
    "    return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bae9989",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_reg = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008af7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBatchReg(): #gt_cons_cpy\n",
    "    \n",
    "    batch_xl = np.zeros((batch_size_reg,3,patch_size,patch_size))\n",
    "    \n",
    "    batch_gt = np.zeros((batch_size_reg,1,patch_size,patch_size))\n",
    "    \n",
    "    batch_pred = np.zeros((batch_size_reg,1,patch_size,patch_size))\n",
    "    \n",
    "    \n",
    "    for el in range(batch_size_reg):\n",
    "        \n",
    "        if(el % 10 == 0):\n",
    "            \n",
    "            ridx = np.random.randint(0,len(left_list),1)\n",
    "            left_im = left_list[ridx[0]]\n",
    "            gt_im = gt_list[ridx[0]]\n",
    "            pred_im = disp_ref_list[ridx[0]]\n",
    "        \n",
    "        \n",
    "        h,w,c = left_im.shape\n",
    "        r_h = 0\n",
    "        r_w = 0\n",
    "        d = 0\n",
    "        \n",
    "#        print('Draw for random position')\n",
    "        #also check height! should not draw corner pixels!!\n",
    "        while True:\n",
    "            \n",
    "            r_h = random.sample(range(ps_h,h-(ps_h+1)), 1)\n",
    "            r_w = random.sample(range(ps_h,w-(ps_h+1)),1)   \n",
    "            \n",
    "            if(not np.isnan(gt_im[r_h,r_w])):\n",
    "                d = int(np.round(gt_im[r_h,r_w]))\n",
    "                if((r_w[0]-ps_h-d-1) >= 0):\n",
    "                     if((r_w[0]+(ps_h+1)-d+1) <= w):\n",
    "                        break\n",
    "        \n",
    "        \n",
    "        cur_left = left_im[r_h[0]-ps_h:r_h[0]+(ps_h+1), r_w[0]-ps_h:r_w[0]+(ps_h+1),:]\n",
    "        \n",
    "        cur_gt = gt_im[r_h[0]-ps_h:r_h[0]+(ps_h+1), r_w[0]-ps_h:r_w[0]+(ps_h+1)]\n",
    "        \n",
    "        cur_pred = pred_im[r_h[0]-ps_h:r_h[0]+(ps_h+1), r_w[0]-ps_h:r_w[0]+(ps_h+1)]\n",
    "\n",
    "        batch_gt[el,:,:,:] =  cur_gt.astype(np.float32)\n",
    "        \n",
    "        batch_pred[el,:,:,:] =  cur_pred.astype(np.float32)\n",
    "        \n",
    "        \n",
    "    return batch_gt, batch_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb34920",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "disp_ref_list = loadRefineDisp()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a52ad3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(refreg.parameters())\n",
    "\n",
    "optimizer_G = optim.Adam(params, lr)\n",
    "\n",
    "best_err = 10000000000\n",
    "\n",
    "early_stopping_count = 0\n",
    "\n",
    "i = 0\n",
    "\n",
    "batch_gt, batch_pred = getBatchReg()\n",
    "loss_list = []\n",
    "\n",
    "avg_2_pe = 10000\n",
    "\n",
    "while(True):\n",
    "    \n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    optimizer_G.zero_grad()\n",
    "    \n",
    "\n",
    "    predT = Variable(Tensor(batch_pred))\n",
    "\n",
    "    outT = refreg(predT)\n",
    "\n",
    "    batch_gtT = Variable(Tensor(batch_gt))\n",
    "\n",
    "    loss = RegLoss(batch_gtT, predT, outT).mean()\n",
    "    \n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    loss_list.append(loss.cpu().data.numpy())\n",
    "    \n",
    "    \n",
    "    #loss_list.append(ce_loss.cpu().data.numpy())\n",
    "    #ce_loss.backward()\n",
    "    optimizer_G.step()\n",
    "    \n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "    #if(i % 100 == 0):\n",
    "    \n",
    "    batch_gt, batch_pred = getBatchReg()\n",
    "        \n",
    "        \n",
    "    if(i %  10000 == 0): #20000\n",
    "        \n",
    "        #batch_xl, batch_gt, batch_pred, label_gt, label_gt_int = getBatch()\n",
    "        \n",
    "        print('--------------------')\n",
    "        print(\"Epoch: {}\".format(i))\n",
    "        print(\"CE-loss: {}\".format(loss.cpu().data.numpy()))\n",
    "        \n",
    "        two_pe = EvalReg(i)\n",
    "        if(two_pe < avg_2_pe):\n",
    "            print(\"Improved: {}\".format(two_pe))\n",
    "            avg_2_pe = two_pe\n",
    "            torch.save(refreg.state_dict(), w_reg_folder + model_name + '_best%04i' %(i) + 'e%04f' %(avg_2_pe)) \n",
    "            early_stopping_count = 0\n",
    "            \n",
    "        else:\n",
    "            print(\"Did not improve\")\n",
    "            early_stopping_count = early_stopping_count + 1\n",
    "        if(early_stopping_count >= 20):\n",
    "            print(\"Stop Training\")\n",
    "            break\n",
    "        print('--------------------')\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070c3c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "refreg.load_state_dict(torch.load('/media/HDD/Self-Sup-Github/SAda-Net/weights/Trained/refReg/mb_60f40s_best230000e24.911293'))\n",
    "\n",
    "two_pe = EvalReg(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37966d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c38ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/media/HDD/Self-Sup-Github/SAda-Net/OUTNEW/'\n",
    "\n",
    "avg_4_pe = 0.0\n",
    "avg_2_pe = 0.0\n",
    "avg_1_pe = 0.0\n",
    "avg_pf_pe = 0.0\n",
    "\n",
    "for i in range(len(disp_ref_list)):\n",
    "\n",
    "    dispT = Variable(Tensor(disp_ref_list[i].copy()))\n",
    "\n",
    "    dispTfilt = median_blur(dispT.unsqueeze(0).unsqueeze(0), (5,5))\n",
    "\n",
    "    filtered_disp = dispTfilt.squeeze().cpu().data.numpy()\n",
    "\n",
    "    five_pe, four_pe, three_pe, two_pe, one_pe, pf_pe = calcEPE(filtered_disp, gt_list[i])\n",
    "    \n",
    "    avg_4_pe = avg_4_pe + four_pe\n",
    "    avg_2_pe = avg_2_pe + two_pe\n",
    "    avg_1_pe = avg_1_pe + one_pe\n",
    "    avg_pf_pe = avg_pf_pe + pf_pe\n",
    "    \n",
    "    name = s_name_list[i]\n",
    "    writePFM(folder + '%s_e%06f.pfm' %(s_name_list[i], two_pe), filtered_disp.astype(np.float32))\n",
    "    \n",
    "    \n",
    "avg_4_pe = avg_4_pe / len(disp_ref_list)\n",
    "avg_2_pe = avg_2_pe / len(disp_ref_list)\n",
    "avg_1_pe = avg_1_pe / len(disp_ref_list)\n",
    "avg_pf_pe = avg_pf_pe / len(disp_ref_list)\n",
    "\n",
    "print(\"Avg. 4-PE {}\".format(avg_4_pe))\n",
    "print(\"Avg. 2-PE {}\".format(avg_2_pe))\n",
    "print(\"Avg. 1-PE {}\".format(avg_1_pe))\n",
    "print(\"Avg. 0.5-PE {}\".format(avg_pf_pe))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
