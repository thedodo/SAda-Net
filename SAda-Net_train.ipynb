{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FCDSN train notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) DI Dominik Hirner BSc. \n",
    "Institute for graphics and vision (ICG)\n",
    "University of Technology Graz, Austria\n",
    "E-mail: dominik.hirner@icg.tugraz.at\n",
    "\n",
    "This notebook is the equivalent to the FCDSN_train.py script in the root folder of this repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "import numpy.matlib\n",
    "import numpy as np\n",
    "import cv2\n",
    "import re\n",
    "from termcolor import colored\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torchvision  #for deformconv2\n",
    "\n",
    "\n",
    "import random\n",
    "import configparser\n",
    "from typing import Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from guided_filter_pytorch.guided_filter import GuidedFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KITTI, MB or ETH\n",
    "dataset = 'MB'\n",
    "#used as prefix for saved weights\n",
    "model_name = 'mb_60f40s'\n",
    "\n",
    "#folder with training data\n",
    "\n",
    "#input_folder = '/media/HDD/TrainingsData/MB_H/testH/*/'\n",
    "input_folder = '/media/HDD/TrainingsData/MB_H/trainingHDisp/*/'\n",
    "#input_folder = '/media/HDD/TrainingsData/MB_H/trainingHDispEL/*/'\n",
    "\n",
    "#input_folder = '/media/HDD/Self-Sup_Stereo/OwnStereoNW/Out/Train/post-proc/NewTrainset/trainingHDisp/*/'\n",
    "\n",
    "\n",
    "#input_folder = '/media/HDD/TrainingsData/MB_H/trainingHDisp/*/'\n",
    "#input_folder = '/media/HDD/TrainingsData/MB_H/trainingHDispEL/*/'\n",
    "\n",
    "#input_folder = '/media/HDD/TrainingsData/MB_Q/*/'\n",
    "\n",
    "save_folder_branch = '/media/HDD/Self_supervised_BCKUP/weights/branch/'\n",
    "save_folder_simb = '/media/HDD/Self_supervised_BCKUP/weights/simB/'\n",
    "\n",
    "out_folder = '/media/HDD/Self_supervised_BCKUP/Out/'\n",
    "\n",
    "\n",
    "lr = 0.00006\n",
    "\n",
    "\n",
    "batch_size = 100\n",
    "nr_batches = 60\n",
    "nr_epochs = 20000000\n",
    "num_feat_branch = 46#60#60#46 #60\n",
    "num_feat_simb = 45#40#40#45#42 #50\n",
    "\n",
    "save_weights = 100\n",
    "\n",
    "#needs to be odd\n",
    "#size of patch-crops fed into the networ\n",
    "patch_size = 21\n",
    "ps_h = int(patch_size/2)\n",
    "\n",
    "#range for offset of o_neg\n",
    "r_low = 1\n",
    "r_high = 25#40#25#25\n",
    "\n",
    "\n",
    "#/media/HDD/TrainingsData/GRSS-Data/sat_data_orig/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disparity_sintel(filename):\n",
    "    \"\"\" Return disparity read from filename. \"\"\"\n",
    "    f_in = np.array(Image.open(filename))\n",
    "    d_r = f_in[:,:,0].astype('float64')\n",
    "    d_g = f_in[:,:,1].astype('float64')\n",
    "    d_b = f_in[:,:,2].astype('float64')\n",
    "\n",
    "    depth = d_r * 4 + d_g / (2**6) + d_b / (2**14)\n",
    "    return depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseBranch64(nn.Module):\n",
    "    def __init__(self,img_ch=3):\n",
    "        super(SiameseBranch64,self).__init__()\n",
    "\n",
    "        self.Tanh = nn.Tanh() \n",
    "        self.Conv1 = nn.Conv2d(img_ch, num_feat_branch, kernel_size = 3,stride=1,padding = 1,dilation = 1, bias=True)      \n",
    "        self.Conv2 = nn.Conv2d(num_feat_branch, num_feat_branch, kernel_size = 3,stride=1,padding = 1,dilation = 1, bias=True)\n",
    "        self.Conv3 = nn.Conv2d(2*num_feat_branch, num_feat_branch, kernel_size = 3,stride=1,padding = 1,dilation = 1, bias=True)\n",
    "        self.Conv4 = nn.Conv2d(3*num_feat_branch, 60, kernel_size = 3,stride=1,padding = 1,dilation = 1,bias=True)  \n",
    "\n",
    "\n",
    "    def forward(self,x_in):\n",
    "\n",
    "        x1 = self.Conv1(x_in) \n",
    "        x1 = self.Tanh(x1)\n",
    "\n",
    "        x2 = self.Conv2(x1) \n",
    "        x2 = self.Tanh(x2)\n",
    "\n",
    "        d2 = torch.cat((x1,x2),dim=1)\n",
    "\n",
    "        x3 = self.Conv3(d2) \n",
    "        x3 = self.Tanh(x3)\n",
    "\n",
    "        d3 = torch.cat((x1,x2,x3),dim=1)\n",
    "\n",
    "        x4 = self.Conv4(d3)\n",
    "\n",
    "        return x4\n",
    "\n",
    "branch = SiameseBranch64()\n",
    "branch = branch.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimMeasTanh(nn.Module):\n",
    "    def __init__(self,img_ch=2*60):\n",
    "        super(SimMeasTanh,self).__init__()\n",
    "\n",
    "        self.tanh = nn.Tanh() \n",
    "\n",
    "        self.Conv1 = nn.Conv2d(img_ch, num_feat_simb, kernel_size = 3,stride=1,padding = 1,dilation = 1, bias=True)\n",
    "        self.Conv2 = nn.Conv2d(num_feat_simb, num_feat_simb, kernel_size=3,stride=1,padding = 1,dilation = 1, bias=True)\n",
    "        self.Conv3 = nn.Conv2d(2*num_feat_simb, num_feat_simb, kernel_size=3,stride=1,padding = 1,dilation = 1, bias=True)\n",
    "        self.Conv4 = nn.Conv2d(3*num_feat_simb, num_feat_simb, kernel_size=3,stride=1,padding = 1,dilation = 1, bias=True)\n",
    "        self.Conv5 = nn.Conv2d(4*num_feat_simb, 1, kernel_size=3,stride=1,padding = 1,dilation = 1, bias=True)\n",
    "\n",
    "        #self.conv_offset = nn.Conv2d(1, 18, kernel_size=5, padding=2, bias=None)\n",
    "        #self.mask = nn.Conv2d(1, 9, kernel_size=5, padding=2, bias=None)\n",
    "        #self.deform_conv = torchvision.ops.DeformConv2d(1, 1, kernel_size = 3, padding=1)\n",
    "\n",
    "    def forward(self,x_in):\n",
    "\n",
    "        x1 = self.Conv1(x_in) \n",
    "        x1 = self.tanh(x1)\n",
    "\n",
    "        x2 = self.Conv2(x1) \n",
    "        x2 = self.tanh(x2)\n",
    "\n",
    "        d1 = torch.cat((x1,x2),dim=1)\n",
    "\n",
    "\n",
    "        x3 = self.Conv3(d1) \n",
    "        x3 = self.tanh(x3)\n",
    "\n",
    "        d2 = torch.cat((x1,x2,x3),dim=1)\n",
    "\n",
    "        x4 = self.Conv4(d2) \n",
    "        x4 = self.tanh(x4) \n",
    "        d3 = torch.cat((x1,x2,x3,x4),dim=1)\n",
    "        x5 = self.Conv5(d3)\n",
    "\n",
    "        #needs to be positive for BCE!\n",
    "        #x5 = self.tanh(x5) \n",
    "\n",
    "        #deform_conv block!\n",
    "        #offsets = self.conv_offset(x5)\n",
    "        #mask = self.mask(x5)\n",
    "        #x6 = self.deform_conv(x5,offsets, mask)\n",
    "\n",
    "        return x5\n",
    "\n",
    "\n",
    "simB = SimMeasTanh()\n",
    "simB = simB.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr feat branch:  133092\n"
     ]
    }
   ],
   "source": [
    "pytorch_branch_params = sum(p.numel() for p in branch.parameters() if p.requires_grad)\n",
    "print(\"Nr feat branch: \" ,pytorch_branch_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr feat simB:  159751\n"
     ]
    }
   ],
   "source": [
    "pytorch_simb_params = sum(p.numel() for p in simB.parameters() if p.requires_grad)\n",
    "print(\"Nr feat simB: \" ,pytorch_simb_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr feat all:  292843\n"
     ]
    }
   ],
   "source": [
    "pytorch_total_params = pytorch_branch_params + pytorch_simb_params\n",
    "print(\"Nr feat all: \" ,pytorch_total_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readPFM(file):\n",
    "    file = open(file, 'rb')\n",
    "\n",
    "    color = None\n",
    "    width = None\n",
    "    height = None\n",
    "    scale = None\n",
    "    endian = None\n",
    "\n",
    "    header = file.readline().decode('utf-8').rstrip()\n",
    "    if header == 'PF':\n",
    "        color = True\n",
    "    elif header == 'Pf':\n",
    "        color = False\n",
    "    else:\n",
    "        raise Exception('Not a PFM file.')\n",
    "\n",
    "    dim_match = re.match(r'^(\\d+)\\s(\\d+)\\s$', file.readline().decode('utf-8'))\n",
    "    if dim_match:\n",
    "        width, height = map(int, dim_match.groups())\n",
    "    else:\n",
    "        raise Exception('Malformed PFM header.')\n",
    "\n",
    "    scale = float(file.readline().decode('utf-8').rstrip())\n",
    "    if scale < 0:  # little-endian\n",
    "        endian = '<'\n",
    "        scale = -scale\n",
    "    else:\n",
    "        endian = '>'  # big-endian\n",
    "\n",
    "    data = np.fromfile(file, endian + 'f')\n",
    "    shape = (height, width, 3) if color else (height, width)\n",
    "\n",
    "    data = np.reshape(data, shape)\n",
    "    data = np.flipud(data)\n",
    "    return data, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadETH3D(input_folder):\n",
    "    \n",
    "    left_filelist = glob.glob(input_folder + '/im0.png')\n",
    "    right_filelist = glob.glob(input_folder + '/im1.png')\n",
    "    disp_filelist = glob.glob(input_folder + '/disp0GT.pfm')\n",
    "    \n",
    "    left_filelist = sorted(left_filelist)\n",
    "    right_filelist = sorted(right_filelist)\n",
    "    disp_filelist = sorted(disp_filelist)\n",
    "    \n",
    "    left_list = []\n",
    "    right_list = []\n",
    "    disp_list = []\n",
    "    \n",
    "    for i in range(0,len(left_filelist)):\n",
    "        \n",
    "        cur_left = cv2.imread(left_filelist[i])\n",
    "        cur_right = cv2.imread(right_filelist[i])\n",
    "        cur_disp,_ = readPFM(disp_filelist[i])\n",
    "        \n",
    "        left_list.append(cur_left)\n",
    "        right_list.append(cur_right)\n",
    "        disp_list.append(cur_disp)\n",
    "        \n",
    "    return left_list, right_list, disp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadKitti2015(input_folder):\n",
    "\n",
    "    left_filelist = glob.glob(input_folder + 'image_2/*.png')\n",
    "    right_filelist = glob.glob(input_folder + 'image_3/*.png')\n",
    "    disp_filelist = glob.glob(input_folder + 'disp_noc_0/*.png')\n",
    "    \n",
    "    left_filelist = sorted(left_filelist)\n",
    "    right_filelist = sorted(right_filelist)\n",
    "    disp_filelist = sorted(disp_filelist)\n",
    "\n",
    "    left_elem_list = []\n",
    "    for left_im in left_filelist:\n",
    "\n",
    "        left_im_el = left_im.split('/')[-1]\n",
    "        left_elem_list.append(left_im_el)\n",
    "\n",
    "    left_elem_list = sorted(left_elem_list)\n",
    "\n",
    "\n",
    "    right_elem_list = []\n",
    "    for right_im in right_filelist:\n",
    "\n",
    "        right_im_el = right_im.split('/')[-1]\n",
    "        right_elem_list.append(right_im_el)\n",
    "\n",
    "    right_elem_list = sorted(right_elem_list)\n",
    "\n",
    "    gt_elem_list = []\n",
    "    for gt_im in disp_filelist:\n",
    "\n",
    "        gt_im_el = gt_im.split('/')[-1]\n",
    "        gt_elem_list.append(gt_im_el)\n",
    "\n",
    "    gt_elem_list = sorted(gt_elem_list)\n",
    "\n",
    "    inters_list = set(left_elem_list) & set(right_elem_list) & set(gt_elem_list)\n",
    "   \n",
    "    inters_list = list(inters_list)\n",
    "    left_list = []\n",
    "    right_list = []\n",
    "    disp_list = []\n",
    "    \n",
    "    for i in range(0,len(inters_list)):\n",
    "        \n",
    "        left_im = input_folder + 'image_2/' + inters_list[i]\n",
    "        right_im = input_folder + 'image_3/' + inters_list[i]\n",
    "        disp_im =  input_folder + 'disp_noc_0/' + inters_list[i] \n",
    "       \n",
    "        cur_left = cv2.imread(left_im)\n",
    "        cur_right = cv2.imread(right_im)\n",
    "        cur_disp = cv2.imread(disp_im)\n",
    "        \n",
    "        cur_disp = np.mean(cur_disp,axis=2) \n",
    "        #set 0 (invalid) to inf to be same as MB for Batchloader\n",
    "        cur_disp[np.where(cur_disp == 0.0)] = np.inf\n",
    "        \n",
    "        left_list.append(cur_left)\n",
    "        right_list.append(cur_right)\n",
    "        disp_list.append(cur_disp)\n",
    "        \n",
    "    return left_list, right_list, disp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadKitti2012(input_folder):\n",
    "\n",
    "    left_filelist = glob.glob(input_folder + 'colored_0/*.png')\n",
    "    right_filelist = glob.glob(input_folder + 'colored_1/*.png')\n",
    "    disp_filelist = glob.glob(input_folder + 'disp_noc/*.png')\n",
    "    \n",
    "    left_filelist = sorted(left_filelist)\n",
    "    right_filelist = sorted(right_filelist)\n",
    "    disp_filelist = sorted(disp_filelist)\n",
    "\n",
    "    left_elem_list = []\n",
    "    for left_im in left_filelist:\n",
    "\n",
    "        left_im_el = left_im.split('/')[-1]\n",
    "        left_elem_list.append(left_im_el)\n",
    "\n",
    "    left_elem_list = sorted(left_elem_list)\n",
    "\n",
    "    right_elem_list = []\n",
    "    for right_im in right_filelist:\n",
    "\n",
    "        right_im_el = right_im.split('/')[-1]\n",
    "        right_elem_list.append(right_im_el)\n",
    "\n",
    "    right_elem_list = sorted(right_elem_list)\n",
    "\n",
    "    gt_elem_list = []\n",
    "    for gt_im in disp_filelist:\n",
    "\n",
    "        gt_im_el = gt_im.split('/')[-1]\n",
    "        gt_elem_list.append(gt_im_el)\n",
    "\n",
    "    gt_elem_list = sorted(gt_elem_list)\n",
    "    inters_list = set(left_elem_list) & set(right_elem_list) & set(gt_elem_list)\n",
    "   \n",
    "    inters_list = list(inters_list)\n",
    "    left_list = []\n",
    "    right_list = []\n",
    "    disp_list = []\n",
    "    \n",
    "    for i in range(0,len(inters_list)):\n",
    "        \n",
    "        left_im = input_folder + 'colored_0/' + inters_list[i]\n",
    "        right_im = input_folder + 'colored_1/' + inters_list[i]\n",
    "        disp_im =  input_folder + 'disp_noc/' + inters_list[i] \n",
    "       \n",
    "        cur_left = cv2.imread(left_im)\n",
    "        cur_right = cv2.imread(right_im)\n",
    "        cur_disp = cv2.imread(disp_im)\n",
    "        \n",
    "        cur_disp = np.mean(cur_disp,axis=2) \n",
    "        #set 0 (invalid) to inf to be same as MB for Batchloader\n",
    "        cur_disp[np.where(cur_disp == 0.0)] = np.inf\n",
    "        \n",
    "        left_list.append(cur_left)\n",
    "        right_list.append(cur_right)\n",
    "        disp_list.append(cur_disp)\n",
    "        \n",
    "    return left_list, right_list, disp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadMB(input_folder):\n",
    "    \n",
    "    left_filelist = glob.glob(input_folder + '/im0.png')\n",
    "    right_filelist = glob.glob(input_folder + '/im1.png')\n",
    "    disp_filelist = glob.glob(input_folder + '/disp0GT.pfm')\n",
    "    calib_filelist = glob.glob(input_folder + '/calib.txt')\n",
    "    \n",
    "    left_filelist = sorted(left_filelist)\n",
    "    right_filelist = sorted(right_filelist)\n",
    "    disp_filelist = sorted(disp_filelist)\n",
    "    calib_filelist = sorted(calib_filelist)\n",
    "    \n",
    "    left_list = []\n",
    "    right_list = []\n",
    "    disp_list = []\n",
    "    maxdisp_list = []\n",
    "    s_name_list = []\n",
    "    \n",
    "    for i in range(0,len(left_filelist)):\n",
    "        \n",
    "        cur_left = cv2.imread(left_filelist[i])\n",
    "        cur_right = cv2.imread(right_filelist[i])        \n",
    "        \n",
    "        cur_disp,_ = readPFM(disp_filelist[i])\n",
    "        \n",
    "        cur_disp[np.isnan(cur_disp)] = 0\n",
    "        cur_disp[np.isinf(cur_disp)] = 0\n",
    "        \n",
    "        left_list.append(cur_left)\n",
    "        right_list.append(cur_right)\n",
    "        disp_list.append(cur_disp)\n",
    "        \n",
    "        f = open(calib_filelist[i],'r')\n",
    "        calib = f.read()\n",
    "        max_disp = int(calib.split('\\n')[6].split(\"=\")[1])\n",
    "        \n",
    "        s_name = left_filelist[i].split('/')[-2]\n",
    "        \n",
    "        maxdisp_list.append(max_disp)\n",
    "        s_name_list.append(s_name)\n",
    "        \n",
    "        \n",
    "    return left_list, right_list, disp_list, maxdisp_list, s_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor = torch.cuda.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_binary_kernel(window_size: Tuple[int, int]) -> torch.Tensor:\n",
    "    r\"\"\"Creates a binary kernel to extract the patches. If the window size\n",
    "    is HxW will create a (H*W)xHxW kernel.\n",
    "    \"\"\"\n",
    "    window_range: int = window_size[0] * window_size[1]\n",
    "    kernel: torch.Tensor = torch.zeros(window_range, window_range)\n",
    "    for i in range(window_range):\n",
    "        kernel[i, i] += 1.0\n",
    "    return kernel.view(window_range, 1, window_size[0], window_size[1])\n",
    "\n",
    "\n",
    "def _compute_zero_padding(kernel_size: Tuple[int, int]) -> Tuple[int, int]:\n",
    "    r\"\"\"Utility function that computes zero padding tuple.\"\"\"\n",
    "    computed: Tuple[int, ...] = tuple([(k - 1) // 2 for k in kernel_size])\n",
    "    return computed[0], computed[1]\n",
    "\n",
    "\n",
    "class MedianBlur(nn.Module):\n",
    "    r\"\"\"Blurs an image using the median filter.\n",
    "\n",
    "    Args:\n",
    "        kernel_size (Tuple[int, int]): the blurring kernel size.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: the blurred input tensor.\n",
    "\n",
    "    Shape:\n",
    "        - Input: :math:`(B, C, H, W)`\n",
    "        - Output: :math:`(B, C, H, W)`\n",
    "\n",
    "    Example:\n",
    "        >>> input = torch.rand(2, 4, 5, 7)\n",
    "        >>> blur = kornia.filters.MedianBlur((3, 3))\n",
    "        >>> output = blur(input)  # 2x4x5x7\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size: Tuple[int, int]) -> None:\n",
    "        super(MedianBlur, self).__init__()\n",
    "        self.kernel: torch.Tensor = _compute_binary_kernel(kernel_size)\n",
    "        self.padding: Tuple[int, int] = _compute_zero_padding(kernel_size)\n",
    "\n",
    "    def forward(self, input: torch.Tensor):  # type: ignore\n",
    "        if not torch.is_tensor(input):\n",
    "            raise TypeError(\"Input type is not a torch.Tensor. Got {}\"\n",
    "                            .format(type(input)))\n",
    "        if not len(input.shape) == 4:\n",
    "            raise ValueError(\"Invalid input shape, we expect BxCxHxW. Got: {}\"\n",
    "                             .format(input.shape))\n",
    "        # prepare kernel\n",
    "        b, c, h, w = input.shape\n",
    "        tmp_kernel: torch.Tensor = self.kernel.to(input.device).to(input.dtype)\n",
    "        kernel: torch.Tensor = tmp_kernel.repeat(c, 1, 1, 1)\n",
    "\n",
    "        # map the local window to single vector\n",
    "        features: torch.Tensor = F.conv2d(\n",
    "            input, kernel, padding=self.padding, stride=1, groups=c)\n",
    "        features = features.view(b, c, -1, h, w)  # BxCx(K_h * K_w)xHxW\n",
    "\n",
    "        # compute the median along the feature axis\n",
    "        median: torch.Tensor = torch.median(features, dim=2)[0]\n",
    "        return median\n",
    "\n",
    "# functiona api\n",
    "def median_blur(input: torch.Tensor,\n",
    "                kernel_size: Tuple[int, int]) -> torch.Tensor:\n",
    "    r\"\"\"Blurs an image using the median filter.\n",
    "\n",
    "    See :class:`~kornia.filters.MedianBlur` for details.\n",
    "    \"\"\"\n",
    "    return MedianBlur(kernel_size)(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterCostVolMedianPyt(cost_vol):\n",
    "    \n",
    "    d,h,w = cost_vol.shape\n",
    "    cost_vol = cost_vol.unsqueeze(0)\n",
    "    \n",
    "    for disp in range(d):\n",
    "\n",
    "        cost_vol[:,disp,:,:] = median_blur(cost_vol[:,disp,:,:].unsqueeze(0), (5,5))\n",
    "        \n",
    "    return torch.squeeze(cost_vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterCostVolBilatpyt(cost_vol,left):\n",
    "    \n",
    "    left = np.mean(left,axis=2)\n",
    "    leftT = Variable(Tensor(left))\n",
    "    leftT = leftT.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    d,h,w = cost_vol.shape  \n",
    "    \n",
    "    f = GuidedFilter(8,10).cuda()  #10 #0.001\n",
    "    \n",
    "    for disp in range(d):\n",
    "        cur_slice =  cost_vol[disp,:,:]\n",
    "        cur_slice = cur_slice.unsqueeze(0).unsqueeze(0)\n",
    "        \n",
    "        inputs = [leftT, cur_slice]\n",
    "\n",
    "        test = f(*inputs)\n",
    "        cost_vol[disp,:,:] = np.squeeze(test)\n",
    "        \n",
    "    return cost_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCostVol(branch, simB,left_im,right_im,max_disp, filtered):\n",
    "        \n",
    "    a_h, a_w,c = left_im.shape\n",
    "\n",
    "    left_im = np.transpose(left_im, (2,0,1)).astype(np.uint8)\n",
    "    right_im = np.transpose(right_im, (2,0,1)).astype(np.uint8)\n",
    "    \n",
    "    left_im = np.reshape(left_im, [1,c,a_h,a_w])\n",
    "    right_im = np.reshape(right_im, [1,c,a_h,a_w])\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        left_imT = Variable(Tensor(left_im.astype(np.uint8)))\n",
    "        right_imT = Variable(Tensor(right_im.astype(np.uint8)))\n",
    "        \n",
    "        left_imT = (left_imT-torch.mean(left_imT))/torch.std(left_imT)\n",
    "        right_imT = (right_imT-torch.mean(right_imT))/torch.std(right_imT)        \n",
    "        \n",
    "\n",
    "        left_feat = branch(left_imT)\n",
    "        right_feat = branch(right_imT)\n",
    "        \n",
    "        _,f,h,w = left_feat.shape\n",
    "        \n",
    "        cost_vol = np.zeros((max_disp+1,a_h,a_w))\n",
    "        cost_volT = Variable(Tensor(cost_vol))\n",
    "\n",
    "        #0 => max_disp => one less disp!\n",
    "        #python3 apparently cannot have 0 here for disp: right_shift = torch.cuda.FloatTensor(1,f,h,disp).fill_(0)  \n",
    "        for disp in range(0,max_disp+1):\n",
    "\n",
    "            if(disp == 0):\n",
    "                \n",
    "                sim_score = simB(torch.cat((left_feat, right_feat),dim=1))\n",
    "                cost_volT[disp,:,:] = torch.squeeze(sim_score)                \n",
    "            else:\n",
    "                right_shifted = torch.cuda.FloatTensor(1,f,h,w).fill_(0)                      \n",
    "                right_shift = torch.cuda.FloatTensor(1,f,h,disp).fill_(0)  \n",
    "                right_appended = torch.cat([right_shift,right_feat],3)\n",
    "\n",
    "                _,f,h_ap,w_ap = right_appended.shape\n",
    "                right_shifted[:,:,:,:] = right_appended[:,:,:,:(w_ap-disp)]\n",
    "                sim_score = simB(torch.cat((left_feat, right_shifted),dim=1))\n",
    "                cost_volT[disp,:,:] = torch.squeeze(sim_score)              \n",
    "\n",
    "    return cost_volT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCostVolRL(branch, simB, left_im,right_im,max_disp, filtered):\n",
    "\n",
    "    a_h, a_w,c = left_im.shape\n",
    "\n",
    "    left_im = np.transpose(left_im, (2,0,1)).astype(np.uint8)\n",
    "    right_im = np.transpose(right_im, (2,0,1)).astype(np.uint8)\n",
    "    \n",
    "    left_im = np.reshape(left_im, [1,c,a_h,a_w])\n",
    "    right_im = np.reshape(right_im, [1,c,a_h,a_w])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        left_imT = Variable(Tensor(left_im))\n",
    "        right_imT = Variable(Tensor(right_im))\n",
    "\n",
    "        left_imT = (left_imT-torch.mean(left_imT))/torch.std(left_imT)\n",
    "        right_imT = (right_imT-torch.mean(right_imT))/torch.std(right_imT)        \n",
    "        \n",
    "        left_feat = branch(left_imT)\n",
    "        right_feat = branch(right_imT)\n",
    "\n",
    "\n",
    "        _,f,h,w = left_feat.shape\n",
    "        cost_vol = np.zeros((max_disp+1,a_h,a_w))\n",
    "        \n",
    "        cost_volT = Variable(Tensor(cost_vol))\n",
    "\n",
    "        for disp in range(0,max_disp+1):\n",
    "\n",
    "            if(disp == 0):\n",
    "                sim_score = simB(torch.cat((left_feat, right_feat),dim=1))\n",
    "                cost_volT[disp,:,:] = torch.squeeze(sim_score) \n",
    "            else:    \n",
    "                left_shifted = torch.cuda.FloatTensor(1,f,h,w).fill_(0)\n",
    "                left_shift = torch.cuda.FloatTensor(1,f,h,disp).fill_(0)\n",
    "                left_appended = torch.cat([left_feat,left_shift],3)\n",
    "\n",
    "                _,f,h_ap,w_ap = left_appended.shape\n",
    "                left_shifted[:,:,:,:] = left_appended[:,:,:,disp:w_ap]\n",
    "            \n",
    "                sim_score = simB(torch.cat((left_shifted, right_feat),dim=1))\n",
    "                cost_volT[disp,:,:] = torch.squeeze(sim_score)\n",
    "                \n",
    "    return cost_volT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCostVolAllTogetherSimB(left_im,right_im,max_disp, filtered):    \n",
    "    \n",
    "    a_h, a_w,c = left_im.shape\n",
    "    left_im = np.transpose(left_im, (2,0,1)).astype(np.uint8)\n",
    "    right_im = np.transpose(right_im, (2,0,1)).astype(np.uint8)\n",
    "    \n",
    "    left_im = np.reshape(left_im, [1,c,a_h,a_w])\n",
    "    right_im = np.reshape(right_im, [1,c,a_h,a_w])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        left_imT = Variable(Tensor(left_im.astype(np.uint8)))\n",
    "        right_imT = Variable(Tensor(right_im.astype(np.uint8)))\n",
    "\n",
    "        left_imT = (left_imT-torch.mean(left_imT))/torch.std(left_imT)\n",
    "        right_imT = (right_imT-torch.mean(right_imT))/torch.std(right_imT)\n",
    "\n",
    "        left_feat = branch(left_imT)\n",
    "        right_feat = branch(right_imT)\n",
    "        \n",
    "        _,f,h,w = left_feat.shape\n",
    "        \n",
    "        cost_volL = np.zeros((max_disp+1,a_h,a_w))\n",
    "        cost_volLT = Variable(Tensor(cost_volL))   \n",
    "    \n",
    "        cost_volR = np.zeros((max_disp+1,a_h,a_w))\n",
    "        cost_volRT = Variable(Tensor(cost_volR))   \n",
    "    \n",
    "        #0 => max_disp => one less disp!\n",
    "        for disp in range(0,max_disp+1):\n",
    "            \n",
    "            if(disp == 0):\n",
    "                sim_score_l = simB(torch.cat((left_feat, right_feat),dim=1))\n",
    "                sim_score_r = simB(torch.cat((left_feat, right_feat),dim=1))\n",
    "\n",
    "                cost_volRT[disp,:,:] = torch.squeeze(sim_score_l) \n",
    "                cost_volLT[disp,:,:] = torch.squeeze(sim_score_r) \n",
    "\n",
    "            else:\n",
    "                \n",
    "                left_shifted = torch.roll(left_feat, -disp, dims = 3) \n",
    "                left_shifted[:,:,:,w-disp:w] = 0\n",
    "                sim_score_right = simB(torch.cat((left_shifted, right_feat),dim=1))\n",
    "                cost_volRT[disp,:,:] = torch.squeeze(sim_score_right) \n",
    "                \n",
    "    \n",
    "                right_shifted = torch.roll(right_feat, disp, dims = 3) \n",
    "                right_shifted[:,:,:,0:disp] = 0\n",
    "                sim_score_left = simB(torch.cat((left_feat, right_shifted),dim=1))\n",
    "                cost_volLT[disp,:,:] = torch.squeeze(sim_score_left) \n",
    "                \n",
    "\n",
    "    return cost_volLT, cost_volRT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestImage(branch, simB, fn_left, fn_right, max_disp, filtered, lr_check, dataset):\n",
    "    \n",
    "    left = cv2.imread(fn_left)\n",
    "    right = cv2.imread(fn_right)\n",
    "    \n",
    "    disp_map = []\n",
    "    \n",
    "    if(filtered):\n",
    "        \n",
    "        cost_volLT, cost_volRT = createCostVolAllTogetherSimB(left,right,max_disp, True)\n",
    "        \n",
    "        cost_vol_filteredn = filterCostVolBilatpyt(cost_volLT,left)\n",
    "        cost_vol_filteredn = np.squeeze(cost_vol_filteredn.cpu().data.numpy())                \n",
    "        disp = np.argmax(cost_vol_filteredn, axis=0) \n",
    "        \n",
    "        #del cost_vol\n",
    "        #del cost_vol_filteredn\n",
    "        #torch.cuda.empty_cache()              \n",
    "        \n",
    "        if(lr_check):\n",
    "            #cost_vol_RL = createCostVolRL(branch, simB,left,right,max_disp, True)\n",
    "            \n",
    "            cost_vol_RL_fn = filterCostVolBilatpyt(cost_volRT,right)\n",
    "            cost_vol_RL_fn = np.squeeze(cost_vol_RL_fn.cpu().data.numpy())\n",
    "            \n",
    "            disp_map_RL = np.argmax(cost_vol_RL_fn, axis=0)  \n",
    "            disp_map = LR_Check(disp.astype(np.float32), disp_map_RL.astype(np.float32), dataset)\n",
    "            \n",
    "            #del cost_vol_RL\n",
    "            #del cost_vol_RL_fn\n",
    "            #torch.cuda.empty_cache()              \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        cost_volLT, cost_volRT = createCostVolAllTogetherSimB(left,right,max_disp, True)\n",
    "        cost_vol = np.squeeze(cost_volLT.cpu().data.numpy())\n",
    "        disp = np.argmax(cost_vol, axis=0)        \n",
    "        \n",
    "        if(lr_check):\n",
    "            \n",
    "            #cost_vol_RL = createCostVolRL(branch, simB,left,right,max_disp, False)\n",
    "            cost_vol_RL = np.squeeze(cost_volRT.cpu().data.numpy())\n",
    "            disp_map_RL = np.argmax(cost_vol_RL, axis=0)       \n",
    "            disp_map = LR_Check(disp.astype(np.float32), disp_map_RL.astype(np.float32), 'MB')\n",
    "    if(lr_check):\n",
    "        return disp_map, disp, disp_map_RL\n",
    "    else:\n",
    "        return disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writePFM(file, image, scale=1):\n",
    "    file = open(file, 'wb')\n",
    "\n",
    "    color = None\n",
    "\n",
    "    if image.dtype.name != 'float32':\n",
    "        raise Exception('Image dtype must be float32.')\n",
    "\n",
    "    image = np.flipud(image)\n",
    "\n",
    "    if len(image.shape) == 3 and image.shape[2] == 3:  # color image\n",
    "        color = True\n",
    "    elif len(image.shape) == 2 or len(image.shape) == 3 and image.shape[2] == 1:  # greyscale\n",
    "        color = False\n",
    "    else:\n",
    "        raise Exception('Image must have H x W x 3, H x W x 1 or H x W dimensions.')\n",
    "\n",
    "    file.write('PF\\n'.encode() if color else 'Pf\\n'.encode())\n",
    "    file.write('%d %d\\n'.encode() % (image.shape[1], image.shape[0]))\n",
    "\n",
    "    endian = image.dtype.byteorder\n",
    "\n",
    "    if endian == '<' or endian == '=' and sys.byteorder == 'little':\n",
    "        scale = -scale\n",
    "\n",
    "    file.write('%f\\n'.encode() % scale)\n",
    "\n",
    "    image.tofile(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writePFMcyt(file, image, scale=1):\n",
    "    file = open(file, 'wb')\n",
    "\n",
    "    color = None\n",
    "\n",
    "    image = np.flipud(image)\n",
    "\n",
    "    if len(image.shape) == 3 and image.shape[2] == 3:  # color image\n",
    "        color = True\n",
    "    elif len(image.shape) == 2 or len(image.shape) == 3 and image.shape[2] == 1:  # greyscale\n",
    "        color = False\n",
    "    else:\n",
    "        raise Exception('Image must have H x W x 3, H x W x 1 or H x W dimensions.')\n",
    "\n",
    "    file.write('PF\\n'.encode() if color else 'Pf\\n'.encode())\n",
    "    file.write('%d %d\\n'.encode() % (image.shape[1], image.shape[0]))\n",
    "\n",
    "    endian = image.dtype.byteorder\n",
    "\n",
    "    scale = -scale\n",
    "\n",
    "    file.write('%f\\n'.encode() % scale)\n",
    "    image.tofile(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%cython -a\n",
    "import numpy as np\n",
    "import cython\n",
    "#@cython.boundscheck(False)\n",
    "#@cython.nonecheck(False)\n",
    "@cython.wraparound(False)\n",
    "cpdef float[:, :] FillIncons(unsigned char[:, :] mask, float[:, :] disp):\n",
    "\n",
    "    cpdef int curnan, curnanh, curnanw,curw, w, h ,left, right, above, under, r_above, l_above, r_under, l_under\n",
    "    cpdef float fill  \n",
    "    cpdef int max_search\n",
    "    \n",
    "    max_search = 30\n",
    "    \n",
    "    w = mask.shape[1]\n",
    "    h = mask.shape[0] \n",
    "    \n",
    "    #BG\n",
    "    idc = np.argwhere(np.isnan(disp))    \n",
    "    for curnan in range(len(idc)):\n",
    "        \n",
    "        curnanh = idc[curnan][0]\n",
    "        curnanw = idc[curnan][1]        \n",
    "        if(mask[curnanh,curnanw] == 0):\n",
    "            \n",
    "            #whole scanline is nan => disp is 0\n",
    "            if(all(np.isnan(disp[curnanh,:]))):\n",
    "                #hole line set to 0!\n",
    "                disp[curnanh,:] = 0.0\n",
    "                \n",
    "            #all px to the left are NaN\n",
    "            if(all(np.isnan(disp[curnanh,0:curnanw]))):\n",
    "                #go to the right\n",
    "                curw = curnanw\n",
    "                fill = 0\n",
    "                while(np.isnan(disp[curnanh,curw]) and mask[curnanh,curnanw] == 0):\n",
    "                    curw = curw +1\n",
    "                    fill = disp[curnanh,curw]\n",
    "                disp[curnanh,curnanw] = fill\n",
    "                \n",
    "            #else go left\n",
    "            else:\n",
    "                curw = curnanw\n",
    "                fill = 0\n",
    "                while(np.isnan(disp[curnanh,curw]) and mask[curnanh,curnanw] == 0):\n",
    "                    curw = curw -1\n",
    "                    fill = disp[curnanh,curw]\n",
    "                disp[curnanh,curnanw] = fill \n",
    "    \n",
    "    #FG\n",
    "    idcFG = np.argwhere(np.isnan(disp))\n",
    "    for curnan in range(len(idcFG)):\n",
    "        \n",
    "        curnanh = idcFG[curnan][0]\n",
    "        curnanw = idcFG[curnan][1]\n",
    "      \n",
    "        left = 0\n",
    "        right = 0\n",
    "        above = 0\n",
    "        under = 0\n",
    "\n",
    "        r_above = 0\n",
    "        l_above = 0\n",
    "        r_under = 0\n",
    "        l_under = 0      \n",
    "        \n",
    "        \n",
    "        if(curnanw == 0):\n",
    "            left = 0\n",
    "        else:\n",
    "            left = int(disp[curnanh,curnanw-1])\n",
    "            \n",
    "        counter = 0                                    \n",
    "        while(np.isnan(disp[curnanh,curnanw+counter])):\n",
    "            counter = counter +1                       \n",
    "            if((curnanw+counter) >= w or counter >= max_search):\n",
    "                right = 0\n",
    "                break\n",
    "            right = int(disp[curnanh,curnanw+counter])\n",
    "        \n",
    "        counter = 0                                    \n",
    "        while(np.isnan(disp[curnanh+counter,curnanw])):\n",
    "            counter = counter +1                       \n",
    "            if((curnanh+counter) >= h or counter >= max_search):\n",
    "                above = 0\n",
    "                break       \n",
    "            above = int(disp[curnanh+counter,curnanw])\n",
    "             \n",
    "        if(curnanh == 0):\n",
    "            under = 0\n",
    "        else:\n",
    "            under = int(disp[curnanh-1,curnanw])\n",
    "        \n",
    "        \n",
    "        counter = 0                                    \n",
    "        while(np.isnan(disp[curnanh+counter,curnanw+counter])):\n",
    "            counter = counter +1\n",
    "            if((curnanh+counter) >= h or counter >= max_search):\n",
    "                r_above = 0\n",
    "                break\n",
    "            if((curnanw+counter) >= w):\n",
    "                r_above = 0\n",
    "                break                        \n",
    "            r_above = int(disp[curnanh+counter,curnanw+counter])     \n",
    "        \n",
    "        if(curnanh == 0 or curnanw == 0):\n",
    "            l_under = 0\n",
    "        else:\n",
    "            l_under = int(disp[curnanh-1,curnanw-1])\n",
    "             \n",
    "        \n",
    "        counter = 0      \n",
    "        while(np.isnan(disp[curnanh+counter,curnanw-counter])):\n",
    "            counter = counter +1\n",
    "            if((curnanh+counter) >= h):\n",
    "                l_above = 0\n",
    "                break\n",
    "            if((curnanw-counter) <= 0 or counter >= max_search):\n",
    "                l_above = 0\n",
    "                break\n",
    "            l_above = int(disp[curnanh+counter,curnanw-counter])\n",
    "\n",
    "        if(curnanh == 0 or curnanw >= w-1):\n",
    "            r_under = 0\n",
    "        else:\n",
    "            r_under = int(disp[curnanh-1,curnanw+1])\n",
    "         \n",
    "        fill = np.median([left,right,above,under,r_above,l_above,r_under,l_under])\n",
    "        disp[curnanh,curnanw] = fill\n",
    "\n",
    "    return disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestMB(branch, simB, input_folder, epoch, output_folder,filtered,lr_check,fill_incons, save):\n",
    "    \n",
    "    avg_five_pe = 0.0\n",
    "    avg_four_pe = 0.0 \n",
    "    avg_three_pe = 0.0 \n",
    "    avg_two_pe = 0.0\n",
    "    avg_one_pe = 0.0\n",
    "    avg_pf_pe = 0.0\n",
    "    algo_name = 'FC_sim_'\n",
    "    nr_incons_tot = 0.0\n",
    "\n",
    "    nr_samples = len(glob.glob(input_folder))\n",
    "    \n",
    "    for samples in glob.glob(input_folder):\n",
    "\n",
    "        gt,_ = readPFM(samples + 'disp0GT.pfm')\n",
    "\n",
    "        f = open(samples + 'calib.txt','r')\n",
    "        calib = f.read()\n",
    "        max_disp = int(calib.split('\\n')[6].split(\"=\")[1])\n",
    "        s_name = samples.split('/')[-2]\n",
    "        print(\"{}: {}\".format(s_name, str(max_disp)))\n",
    "\n",
    "        disp = None\n",
    "        disp_s = None\n",
    "\n",
    "        if(lr_check):\n",
    "            \n",
    "            disp_s,disp, disp_rl = TestImage(branch, simB, samples + '/im0.png', samples + '/im1.png', max_disp, filtered, lr_check, 'MB')\n",
    "\n",
    "            nr_incons = np.count_nonzero(np.isnan(disp_s))\n",
    "            nr_incons_tot = nr_incons_tot + nr_incons\n",
    "            \n",
    "        else:\n",
    "            disp = TestImage(branch, simB, samples + '/im0.png', samples + '/im1.png', max_disp, filtered, lr_check, 'MB')\n",
    "            \n",
    "        if(fill_incons):\n",
    "            \n",
    "            disp_arr = np.array(disp_s)\n",
    "            im_disp = Image.fromarray(disp_arr) \n",
    "            im_disp = np.dstack((im_disp, im_disp, im_disp)).astype(np.uint8)    \n",
    "\n",
    "            h,w = disp_arr.shape\n",
    "\n",
    "            shifted = cv2.pyrMeanShiftFiltering(im_disp, 7, 7)\n",
    "\n",
    "            gray = cv2.cvtColor(shifted, cv2.COLOR_BGR2GRAY)\n",
    "            thresh = cv2.threshold(gray, 0, 1,\n",
    "            cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "            ##cv2.imwrite(im_to_save + 'bilat_and_med_mask.png',thresh * 255)\n",
    "\n",
    "            disp_filled = FillIncons(thresh, disp_arr)\n",
    "            disp_filled = np.array(disp_filled)        \n",
    "            \n",
    "\n",
    "        disp = np.array(disp)\n",
    "\n",
    "        gt = np.array(gt)\n",
    "        \n",
    "        if(fill_incons):\n",
    "            \n",
    "            five_pe, four_pe, three_pe, two_pe, one_pe, pf_pe = calcEPE(disp_filled, gt)        \n",
    "\n",
    "\n",
    "            avg_five_pe = avg_five_pe + five_pe\n",
    "            avg_four_pe = avg_four_pe +  four_pe\n",
    "            avg_three_pe = avg_three_pe + three_pe\n",
    "            avg_two_pe = avg_two_pe + two_pe\n",
    "            avg_one_pe = avg_one_pe + one_pe\n",
    "            avg_pf_pe = avg_pf_pe + pf_pe        \n",
    "\n",
    "        else:\n",
    "            \n",
    "            five_pe, four_pe, three_pe, two_pe, one_pe, pf_pe = calcEPE(disp, gt)\n",
    "\n",
    "            avg_five_pe = avg_five_pe + five_pe\n",
    "            avg_four_pe = avg_four_pe +  four_pe\n",
    "            avg_three_pe = avg_three_pe + three_pe\n",
    "            avg_two_pe = avg_two_pe + two_pe\n",
    "            avg_one_pe = avg_one_pe + one_pe\n",
    "            avg_pf_pe = avg_pf_pe + pf_pe        \n",
    "\n",
    "        if(save):\n",
    "            writePFMcyt(out_folder +  s_name + '%06d_e%06f.pfm' %(epoch,two_pe),disp.astype(np.float32))\n",
    "            if(lr_check):\n",
    "                writePFMcyt(output_folder + algo_name + s_name + '%06d_s.pfm' %epoch,disp_s) \n",
    "                writePFMcyt(output_folder + algo_name + s_name + '%06d_rl.pfm' %epoch,disp_rl.astype(np.float32)) \n",
    "            if(fill_incons):\n",
    "                writePFMcyt(out_folder +  s_name + '%06d_e%06f_filled.pfm' %(epoch,two_pe),disp_filled.astype(np.float32))\n",
    "\n",
    "    avg_four_pe = avg_four_pe / nr_samples\n",
    "    avg_two_pe = avg_two_pe / nr_samples\n",
    "    avg_one_pe = avg_one_pe / nr_samples\n",
    "    avg_pf_pe = avg_pf_pe / nr_samples\n",
    "    \n",
    "    print(\"4-PE: {}\".format(avg_four_pe))\n",
    "    print(\"2-PE: {}\".format(avg_two_pe))\n",
    "    print(\"1-PE: {}\".format(avg_one_pe))\n",
    "    print(\"0.5-PE: {}\".format(avg_pf_pe))\n",
    "    print(\"Nr Incons: {}\".format(nr_incons_tot))\n",
    "    \n",
    "    return nr_incons_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestKITTI2015(branch, simB,input_folder, epoch,output_folder,filtered,lr_check,fill_incons,save):\n",
    "        \n",
    "    avg_four_pe = 0.0 \n",
    "    avg_two_pe = 0.0\n",
    "    avg_pf_pe = 0.0 \n",
    "\n",
    "\n",
    "    left_filelist = glob.glob(input_folder + 'image_2/*.png')\n",
    "    right_filelist = glob.glob(input_folder + 'image_3/*.png')\n",
    "    disp_filelist = glob.glob(input_folder + 'disp_noc_0/*.png')\n",
    "\n",
    "    left_filelist = sorted(left_filelist)\n",
    "    right_filelist = sorted(right_filelist)\n",
    "    disp_filelist = sorted(disp_filelist)\n",
    "\n",
    "\n",
    "    left_elem_list = []\n",
    "    for left_im in left_filelist:\n",
    "\n",
    "        left_im_el = left_im.split('/')[-1]\n",
    "        left_elem_list.append(left_im_el)\n",
    "\n",
    "    left_elem_list = sorted(left_elem_list)\n",
    "\n",
    "\n",
    "    right_elem_list = []\n",
    "    for right_im in right_filelist:\n",
    "\n",
    "        right_im_el = right_im.split('/')[-1]\n",
    "        right_elem_list.append(right_im_el)\n",
    "\n",
    "    right_elem_list = sorted(right_elem_list)\n",
    "\n",
    "\n",
    "\n",
    "    gt_elem_list = []\n",
    "    for gt_im in disp_filelist:\n",
    "\n",
    "        gt_im_el = gt_im.split('/')[-1]\n",
    "        gt_elem_list.append(gt_im_el)\n",
    "\n",
    "    gt_elem_list = sorted(gt_elem_list)\n",
    "\n",
    "\n",
    "    inters_list = set(left_elem_list) & set(right_elem_list) & set(gt_elem_list)    \n",
    "    inters_list = list(inters_list)\n",
    "\n",
    "    #only test first 30 for time\n",
    "    for i in range(0,30):  #len(inters_list)\n",
    "\n",
    "        cur_gt = cv2.imread(input_folder + 'disp_noc_0/' +  inters_list[i])\n",
    "        #RGB image\n",
    "        cur_gt = np.mean(cur_gt, axis=2)\n",
    "\n",
    "        cur_gt = cur_gt.astype(np.float32)\n",
    "        cur_gt[np.where(cur_gt == 0)] = np.inf\n",
    "        max_disp =  int(np.ceil(cur_gt[np.isfinite(cur_gt)].max())) + 1\n",
    "        \n",
    "        \n",
    "        s_name = inters_list[i]\n",
    "        disp = None\n",
    "        \n",
    "        if(lr_check):\n",
    "            disp_s,disp, disp_rl = TestImage(branch, simB,input_folder + 'image_2/' + s_name, input_folder + 'image_3/' + s_name, max_disp, filtered, lr_check)   \n",
    "        else:\n",
    "            disp = TestImage(branch, simB,input_folder + 'image_2/' + s_name, input_folder + 'image_3/' + s_name, max_disp, filtered, lr_check) \n",
    "        \n",
    "        disp = np.array(disp)\n",
    "\n",
    "        gt = np.array(cur_gt)\n",
    "        five_pe, four_pe, three_pe, two_pe, one_pe, pf_pe = calcEPE(disp, gt)\n",
    "\n",
    "        avg_four_pe = avg_four_pe +  four_pe\n",
    "        avg_two_pe = avg_two_pe + two_pe\n",
    "        avg_pf_pe = avg_pf_pe + pf_pe        \n",
    "\n",
    "        if(save):\n",
    "            writePFMcyt(output_folder +  s_name + '%06d.pfm' %epoch,disp.astype(np.float32))\n",
    "            if(lr_check):\n",
    "                writePFMcyt(output_folder + s_name + '%06d_s.pfm' %epoch,disp_s) \n",
    "    \n",
    "    avg_two_pe = avg_two_pe / (i+1)\n",
    "    return avg_two_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestKITTI2012(branch, simB, input_folder, epoch, output_folder,filtered,lr_check,fill_incons, save):\n",
    "    \n",
    "        \n",
    "    avg_four_pe = 0.0 \n",
    "    avg_two_pe = 0.0\n",
    "    avg_pf_pe = 0.0 \n",
    "\n",
    "\n",
    "    left_filelist = glob.glob(input_folder + 'colored_0/*.png')\n",
    "    right_filelist = glob.glob(input_folder + 'colored_1/*.png')\n",
    "    disp_filelist = glob.glob(input_folder + 'disp_noc/*.png')\n",
    "\n",
    "    left_filelist = sorted(left_filelist)\n",
    "    right_filelist = sorted(right_filelist)\n",
    "    disp_filelist = sorted(disp_filelist)\n",
    "\n",
    "\n",
    "    left_elem_list = []\n",
    "    for left_im in left_filelist:\n",
    "\n",
    "        left_im_el = left_im.split('/')[-1]\n",
    "        left_elem_list.append(left_im_el)\n",
    "\n",
    "    left_elem_list = sorted(left_elem_list)\n",
    "\n",
    "\n",
    "    right_elem_list = []\n",
    "    for right_im in right_filelist:\n",
    "\n",
    "        right_im_el = right_im.split('/')[-1]\n",
    "        right_elem_list.append(right_im_el)\n",
    "\n",
    "    right_elem_list = sorted(right_elem_list)\n",
    "\n",
    "\n",
    "\n",
    "    gt_elem_list = []\n",
    "    for gt_im in disp_filelist:\n",
    "\n",
    "        gt_im_el = gt_im.split('/')[-1]\n",
    "        gt_elem_list.append(gt_im_el)\n",
    "\n",
    "    gt_elem_list = sorted(gt_elem_list)\n",
    "\n",
    "\n",
    "    inters_list = set(left_elem_list) & set(right_elem_list) & set(gt_elem_list)    \n",
    "    inters_list = list(inters_list)\n",
    "\n",
    "    #only test first 30 for time\n",
    "    for i in range(0,30):  #len(inters_list)\n",
    "\n",
    "        cur_gt = cv2.imread(input_folder + 'disp_noc/' +  inters_list[i])\n",
    "        #RGB image\n",
    "        cur_gt = np.mean(cur_gt, axis=2)\n",
    "\n",
    "        cur_gt = cur_gt.astype(np.float32)\n",
    "        \n",
    "        cur_gt[np.where(cur_gt == 0)] = np.inf\n",
    "        max_disp =  int(np.ceil(cur_gt[np.isfinite(cur_gt)].max())) + 1\n",
    "        \n",
    "        \n",
    "        s_name = inters_list[i]\n",
    "\n",
    "        disp = None\n",
    "        if(lr_check):\n",
    "            disp_s,disp, disp_rl = TestImage(branch, simB, input_folder + 'colored_0/' + s_name, input_folder + 'colored_1/' + s_name, max_disp, filtered, lr_check)   \n",
    "        else:\n",
    "            disp = TestImage(branch, simB, input_folder + 'colored_0/' + s_name, input_folder + 'colored_1/' + s_name, max_disp, filtered, lr_check)   \n",
    "        \n",
    "        disp = np.array(disp)\n",
    "        gt = np.array(cur_gt)\n",
    "        \n",
    "        five_pe, four_pe, three_pe, two_pe, one_pe, pf_pe = calcEPE(disp, gt)\n",
    "\n",
    "\n",
    "        avg_four_pe = avg_four_pe +  four_pe\n",
    "        avg_two_pe = avg_two_pe + two_pe\n",
    "        avg_pf_pe = avg_pf_pe + pf_pe        \n",
    "\n",
    "        if(save):\n",
    "            writePFMcyt(output_folder +  s_name + '%06d.pfm' %epoch,disp.astype(np.float32))\n",
    "            if(lr_check):\n",
    "                writePFMcyt(output_folder + s_name + '%06d_s.pfm' %epoch,disp_s) \n",
    "    \n",
    "    avg_two_pe = avg_two_pe / (i+1)\n",
    "    return avg_two_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestETH(branch, simB, input_folder,epoch, output_folder,filtered,lr_check,fill_incons, save):\n",
    "    \n",
    "    avg_five_pe = 0.0\n",
    "    avg_four_pe = 0.0 \n",
    "    avg_three_pe = 0.0 \n",
    "    avg_two_pe = 0.0\n",
    "    avg_one_pe = 0.0\n",
    "    avg_pf_pe = 0.0\n",
    "    algo_name = 'FC_sim_'\n",
    "\n",
    "    nr_samples = len(glob.glob(input_folder))\n",
    "    for samples in glob.glob(input_folder):\n",
    "\n",
    "        gt,_ = readPFM(samples + 'disp0GT.pfm')\n",
    "\n",
    "        #f = open(samples + 'calib.txt','r')\n",
    "        #calib = f.read()\n",
    "        #take max_disp from gt!!\n",
    "        #max_disp = int(calib.split('\\n')[6].split(\"=\")[1])\n",
    "        max_disp =  int(np.ceil(gt[np.isfinite(gt)].max())) + 1\n",
    "        s_name = samples.split('/')[-2]\n",
    "\n",
    "        disp = None\n",
    "        disp_s = None\n",
    "\n",
    "        if(lr_check):\n",
    "            disp_s,disp,disp_lr = TestImage(branch, simB,samples + '/im0.png', samples + '/im1.png', max_disp, filtered, lr_check)\n",
    "        else:\n",
    "            disp = TestImage(branch, simB,samples + '/im0.png', samples + '/im1.png', max_disp, filtered, lr_check)\n",
    "\n",
    "        disp = np.array(disp)\n",
    "\n",
    "        gt = np.array(gt)\n",
    "        five_pe, four_pe, three_pe, two_pe, one_pe, pf_pe = calcEPE(disp, gt)\n",
    "\n",
    "        avg_five_pe = avg_five_pe + five_pe\n",
    "        avg_four_pe = avg_four_pe +  four_pe\n",
    "        avg_three_pe = avg_three_pe + three_pe\n",
    "        avg_two_pe = avg_two_pe + two_pe\n",
    "        avg_one_pe = avg_one_pe + one_pe\n",
    "        avg_pf_pe = avg_pf_pe + pf_pe        \n",
    "\n",
    "        if(save):\n",
    "            writePFMcyt(output_folder + algo_name + s_name + '%06d.pfm' %epoch,disp.astype(np.float32))\n",
    "            if(lr_check):\n",
    "                writePFMcyt(output_folder + algo_name + s_name + '%06d_s.pfm' %epoch,disp_s) \n",
    "\n",
    "    avg_two_pe = avg_two_pe / nr_samples\n",
    "    return avg_two_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcEPE(disp, gt_fn):\n",
    "    \n",
    "    gt = gt_fn\n",
    "\n",
    "    gt[np.where(gt == np.inf)] = -100\n",
    "    #for loadmb\n",
    "    gt[np.where(gt == 0)] = -100\n",
    "    \n",
    "    mask = gt > 0\n",
    "\n",
    "    disp = disp[mask]\n",
    "    gt = gt[mask]        \n",
    "\n",
    "    nr_px = len(gt)\n",
    "\n",
    "\n",
    "    abs_error_im = np.abs(disp - gt)\n",
    "\n",
    "    five_pe = (float(np.count_nonzero(abs_error_im >= 5.0) ) / nr_px) * 100.0  \n",
    "    four_pe = (float(np.count_nonzero(abs_error_im >= 4.0) ) / nr_px) * 100.0  \n",
    "    three_pe = (float(np.count_nonzero(abs_error_im >= 3.0) ) / nr_px) * 100.0  \n",
    "    two_pe = (float(np.count_nonzero(abs_error_im >= 2.0) ) / nr_px) * 100.0        \n",
    "    one_pe = (float(np.count_nonzero(abs_error_im >= 1.0) ) / nr_px) * 100.0        \n",
    "    pf_pe = (float(np.count_nonzero(abs_error_im >= 0.5) ) / nr_px) * 100.0  \n",
    "        \n",
    "    return five_pe, four_pe, three_pe, two_pe, one_pe, pf_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def getBatch(gt_cons_cpy):\n",
    "    \n",
    "    batch_xl = np.zeros((batch_size,3,patch_size,patch_size))\n",
    "    batch_xr_pos = np.zeros((batch_size,3,patch_size,patch_size))\n",
    "    batch_xr_neg = np.zeros((batch_size,3,patch_size,patch_size))\n",
    "    \n",
    "    for el in range(batch_size):\n",
    "        \n",
    "        \n",
    "        if(el % 10 == 0):\n",
    "            \n",
    "            ridx = np.random.randint(0,len(gt_cons_cpy),1)\n",
    "            left_im = left_list[ridx[0]]\n",
    "            right_im = right_list[ridx[0]]\n",
    "            gt_im = gt_cons_cpy[ridx[0]]\n",
    "        \n",
    "        \n",
    "        h,w,c = left_im.shape\n",
    "        r_h = 0\n",
    "        r_w = 0\n",
    "        d = 0\n",
    "#        print('Draw for random position')\n",
    "        #also check height! should not draw corner pixels!!\n",
    "        while True:\n",
    "            r_h = random.sample(range(ps_h,h-(ps_h+1)), 1)\n",
    "            \n",
    "            r_w = random.sample(range(ps_h,w-(ps_h+1)),1)   \n",
    "            \n",
    "            if(not np.isnan(gt_im[r_h,r_w])):\n",
    "                d = int(np.round(gt_im[r_h,r_w]))\n",
    "                if((r_w[0]-ps_h-d-1) >= 0):\n",
    "                     if((r_w[0]+(ps_h+1)-d+1) <= w):\n",
    "                        break\n",
    "        \n",
    "        d = int(np.round(gt_im[r_h,r_w]))\n",
    "                \n",
    "        cur_left = left_im[r_h[0]-ps_h:r_h[0]+(ps_h+1), r_w[0]-ps_h:r_w[0]+(ps_h+1),:]\n",
    "        #choose offset\n",
    "        \n",
    "        o_pos = 0                \n",
    "        cur_right_pos = right_im[r_h[0]-ps_h:r_h[0]+(ps_h+1), (r_w[0]-ps_h-d+o_pos):(r_w[0]+(ps_h+1)-d+o_pos),:]\n",
    "\n",
    "        \n",
    "        #should not be too close to real match!\n",
    "        o_neg = 0\n",
    "        while True:\n",
    "            #range 6-8??? range(2,6)\n",
    "            o_neg = random.sample(range(r_low,r_high), 1)\n",
    "            if np.random.randint(-1, 1) == -1:\n",
    "                o_neg = -o_neg[0]\n",
    "            else:\n",
    "                o_neg = o_neg[0]\n",
    "            #try without d-+1   and(o_neg != (d-1)) and(o_neg != (d+1))\n",
    "            if((o_neg != d) and ((r_w[0]-ps_h-d+o_neg) > 0)  and ((r_w[0]+(ps_h+1)-d+o_neg) < w)):\n",
    "                break\n",
    "        \n",
    "        \n",
    "        cur_right_neg = right_im[r_h[0]-ps_h:r_h[0]+(ps_h+1), (r_w[0]-ps_h-d+o_neg):(r_w[0]+(ps_h+1)-d+o_neg),:]\n",
    "        \n",
    "        #dice for random orientation for more diversity in train set\n",
    "        \n",
    "        #output becomes way noisier??\n",
    "        #rand = random.randint(0, 3)\n",
    "        #if(rand == 0):\n",
    "        #    continue\n",
    "        #if(rand == 1):\n",
    "        #    cur_left = cv2.flip(cur_left, 0)\n",
    "        #    cur_right_pos = cv2.flip(cur_right_pos, 0)\n",
    "        #    cur_right_neg = cv2.flip(cur_right_neg, 0)\n",
    "        #if(rand == 2):\n",
    "        #    cur_left = cv2.flip(cur_left, 1)\n",
    "        #    cur_right_pos = cv2.flip(cur_right_pos, 1)\n",
    "        #    cur_right_neg = cv2.flip(cur_right_neg, 1)\n",
    "        #if(rand == 3):\n",
    "        #    cur_left = cv2.flip(cur_left, -1)\n",
    "        #    cur_right_pos = cv2.flip(cur_right_pos, -1)\n",
    "        #    cur_right_neg = cv2.flip(cur_right_neg, -1)\n",
    "            \n",
    "        #flipHorizontal = cv2.flip(originalImage, 1)\n",
    "        \n",
    "        \n",
    "        batch_xl[el,:,:,:] =  np.transpose(cur_left, (2,0,1)).astype(np.uint8)\n",
    "        batch_xr_pos[el,:,:,:] = np.transpose(cur_right_pos, (2,0,1)).astype(np.uint8)\n",
    "        batch_xr_neg[el,:,:,:] = np.transpose(cur_right_neg, (2,0,1)).astype(np.uint8)\n",
    "            \n",
    "    return batch_xl, batch_xr_pos, batch_xr_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_hinge_loss(s_p, s_n):\n",
    "    margin = 0.2\n",
    "    relu = torch.nn.ReLU()\n",
    "    relu = relu.cuda()\n",
    "    loss = relu(-((s_p - s_n) - margin))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestMBHP(epoch, output_folder,filtered,lr_check,fill_incons, save):\n",
    "    \n",
    "    s_count = 1\n",
    "    t_count = 0.0\n",
    "\n",
    "    avg_five_pe = 0.0\n",
    "    avg_four_pe = 0.0 \n",
    "    avg_three_pe = 0.0 \n",
    "    avg_two_pe = 0.0\n",
    "    avg_one_pe = 0.0\n",
    "    avg_pf_pe = 0.0\n",
    "    algo_name = 'FC_sim_'\n",
    "\n",
    "    nr_samples = len(glob.glob(input_folder))\n",
    "    for samples in glob.glob(input_folder):\n",
    "\n",
    "        \n",
    "        gt,_ = readPFM(samples + 'disp0GT.pfm')\n",
    "        \n",
    "        f = open(samples + 'calib.txt','r')\n",
    "        calib = f.read()\n",
    "        max_disp = int(calib.split('\\n')[6].split(\"=\")[1])\n",
    "        s_name = samples.split('/')[-2]\n",
    "        #print(s_name)\n",
    "        t = time.time()\n",
    "\n",
    "        disp_name = samples + '/disp0'+algo_name\n",
    "\n",
    "        disp = None\n",
    "        disp_s = None\n",
    "\n",
    "        if(lr_check):\n",
    "            disp_s,disp, disp_rl = TestImage(branch, simB, samples + '/im0.png', samples + '/im1.png', max_disp, filtered, lr_check)\n",
    "        else:\n",
    "            disp = TestImage(samples + '/im0.png', samples + '/im1.png', max_disp, filtered, lr_check)\n",
    "\n",
    "        if(not fill_incons):\n",
    "            s_count = s_count + 1\n",
    "            elapsed = time.time() - t\n",
    "\n",
    "\n",
    "        folder = samples\n",
    "\n",
    "\n",
    "        if(fill_incons):\n",
    "\n",
    "            #do it dynamically\n",
    "            disp_s_arr = np.array(disp_s)\n",
    "            im_disp = Image.fromarray(disp_s_arr) \n",
    "            im_disp = np.dstack((im_disp, im_disp, im_disp)).astype(np.uint8)    \n",
    "\n",
    "            h,w = disp_s.shape\n",
    "\n",
    "            shifted = cv2.pyrMeanShiftFiltering(im_disp, 7, 7)\n",
    "\n",
    "            gray = cv2.cvtColor(shifted, cv2.COLOR_BGR2GRAY)\n",
    "            thresh = cv2.threshold(gray, 0, 1,\n",
    "                cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "            #kernel = np.ones((5,5), np.uint8)\n",
    "            #dilation = cv2.dilate(thresh,kernel,iterations = 2)\n",
    "            #mask = cv2.erode(dilation, kernel, iterations=2)\n",
    "\n",
    "            disp_filled  = FillIncons(thresh, disp_s_arr)\n",
    "            s_count = s_count + 1\n",
    "            elapsed = time.time() - t\n",
    "            disp = np.array(disp)\n",
    "            disp_filled = np.array(disp_filled)\n",
    "            \n",
    "        else:\n",
    "            disp = np.array(disp)\n",
    "\n",
    "        gt = np.array(gt)\n",
    "        if(fill_incons):\n",
    "            five_pe, four_pe, three_pe, two_pe, one_pe, pf_pe = calcEPE(disp_filled, gt)    \n",
    "        else:\n",
    "            five_pe, four_pe, three_pe, two_pe, one_pe, pf_pe = calcEPE(disp, gt)\n",
    "\n",
    "\n",
    "        avg_five_pe = avg_five_pe + five_pe\n",
    "        avg_four_pe = avg_four_pe +  four_pe\n",
    "        avg_three_pe = avg_three_pe + three_pe\n",
    "        avg_two_pe = avg_two_pe + two_pe\n",
    "        avg_one_pe = avg_one_pe + one_pe\n",
    "        avg_pf_pe = avg_pf_pe + pf_pe        \n",
    "        #print(\"Execution time: {}\".format(elapsed))\n",
    "\n",
    "        if(fill_incons):\n",
    "                writePFMcyt(output_folder + algo_name + s_name + '%06d.pfm' %epoch,disp_filled.astype(np.float32)) \n",
    "                writePFMcyt(output_folder + algo_name + s_name + '%06d_s.pfm' %epoch,disp_s) \n",
    "                writePFMcyt(output_folder + algo_name + s_name + '%06d_rl.pfm' %epoch,disp_rl.astype(np.float32)) \n",
    "\n",
    "        else:\n",
    "            if(save):\n",
    "                writePFMcyt(output_folder + algo_name + s_name + '%06d.pfm' %epoch,disp.astype(np.float32))\n",
    "                if(lr_check):\n",
    "                    writePFMcyt(output_folder + algo_name + s_name + '%06d_s.pfm' %epoch,disp_s) \n",
    "                    writePFMcyt(output_folder + algo_name + s_name + '%06d_rl.pfm' %epoch,disp_rl.astype(np.float32)) \n",
    "\n",
    "\n",
    "    avg_four_pe = avg_four_pe / nr_samples\n",
    "    avg_two_pe = avg_two_pe / nr_samples\n",
    "    avg_one_pe = avg_one_pe / nr_samples\n",
    "    avg_pf_pe = avg_pf_pe / nr_samples\n",
    "    \n",
    "    print(\"4-PE: {}\".format(avg_four_pe))\n",
    "    print(\"2-PE: {}\".format(avg_two_pe))\n",
    "    print(\"1-PE: {}\".format(avg_one_pe))\n",
    "    print(\"0.5-PE: {}\".format(avg_pf_pe))\n",
    "    return avg_two_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestMBTest(branch, simB, epoch, output_folder,filtered,lr_check,fill_incons, save):\n",
    "    \n",
    "    s_count = 1\n",
    "    t_count = 0.0\n",
    "\n",
    "    algo_name = 'FC_sim_'\n",
    "\n",
    "    nr_samples = len(glob.glob(input_folder))\n",
    "    for samples in glob.glob(input_folder):\n",
    "\n",
    "        \n",
    "        f = open(samples + 'calib.txt','r')\n",
    "        calib = f.read()\n",
    "        max_disp = int(calib.split('\\n')[6].split(\"=\")[1])\n",
    "        s_name = samples.split('/')[-2]\n",
    "\n",
    "        t = time.time()\n",
    "\n",
    "        disp_name = samples + '/disp0'+algo_name\n",
    "\n",
    "        disp = None\n",
    "        disp_s = None\n",
    "\n",
    "        if(lr_check):\n",
    "            disp_s,disp, disp_rl = TestImage(branch, simB,samples + '/im0.png', samples + '/im1.png', max_disp, filtered, lr_check)\n",
    "        else:\n",
    "            _,disp, disp_rl = TestImage(branch, simB,samples + '/im0.png', samples + '/im1.png', max_disp, filtered, lr_check)\n",
    "\n",
    "        if(not fill_incons):\n",
    "            s_count = s_count + 1\n",
    "            elapsed = time.time() - t\n",
    "\n",
    "\n",
    "        folder = samples\n",
    "\n",
    "\n",
    "        if(fill_incons):\n",
    "\n",
    "            #do it dynamically\n",
    "            disp_s_arr = np.array(disp_s)\n",
    "            im_disp = Image.fromarray(disp_s_arr) \n",
    "            im_disp = np.dstack((im_disp, im_disp, im_disp)).astype(np.uint8)    \n",
    "\n",
    "            h,w = disp_s.shape\n",
    "\n",
    "            shifted = cv2.pyrMeanShiftFiltering(im_disp, 7, 7)\n",
    "\n",
    "            gray = cv2.cvtColor(shifted, cv2.COLOR_BGR2GRAY)\n",
    "            thresh = cv2.threshold(gray, 0, 1,\n",
    "                cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "            #kernel = np.ones((5,5), np.uint8)\n",
    "            #dilation = cv2.dilate(thresh,kernel,iterations = 2)\n",
    "            #mask = cv2.erode(dilation, kernel, iterations=2)\n",
    "\n",
    "            disp_filled  = FillIncons(thresh, disp_s_arr)\n",
    "            s_count = s_count + 1\n",
    "            elapsed = time.time() - t\n",
    "            disp = np.array(disp)\n",
    "            disp_filled = np.array(disp_filled)\n",
    "            \n",
    "        else:\n",
    "            disp = np.array(disp)\n",
    "\n",
    "        if(fill_incons):\n",
    "                writePFMcyt(output_folder + algo_name + s_name + '%06d.pfm' %epoch,disp_filled.astype(np.float32)) \n",
    "                writePFMcyt(output_folder + algo_name + s_name + '%06d_s.pfm' %epoch,disp_s) \n",
    "                writePFMcyt(output_folder + algo_name + s_name + '%06d_rl.pfm' %epoch,disp_rl) \n",
    "                \n",
    "        else:\n",
    "            if(save):\n",
    "                writePFMcyt(output_folder + algo_name + s_name + '%06d.pfm' %epoch,disp.astype(np.float32))\n",
    "                if(lr_check):\n",
    "                    writePFMcyt(output_folder + algo_name + s_name + '%06d_s.pfm' %epoch,disp_s) \n",
    "                    writePFMcyt(output_folder + algo_name + s_name + '%06d_rl.pfm' %epoch,disp_rl) \n",
    "\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCostVolBranch(branch, simB,left_im,right_im,max_disp):\n",
    "    \n",
    "    \n",
    "    k_s = 19\n",
    "    p = 9\n",
    "    \n",
    "    w = np.ones((k_s,k_s)).astype(np.float32)\n",
    "    \n",
    "    weights = Tensor(w)\n",
    "    weights = weights.view(1, 1, k_s, k_s).repeat(1, 1, 1, 1)\n",
    "        \n",
    "    a_h, a_w,c = left_im.shape\n",
    "\n",
    "    left_im = np.transpose(left_im, (2,0,1)).astype(np.uint8)\n",
    "    right_im = np.transpose(right_im, (2,0,1)).astype(np.uint8)\n",
    "    \n",
    "    left_im = np.reshape(left_im, [1,c,a_h,a_w])\n",
    "    right_im = np.reshape(right_im, [1,c,a_h,a_w])\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        left_imT = Variable(Tensor(left_im.astype(np.uint8)))\n",
    "        right_imT = Variable(Tensor(right_im.astype(np.uint8)))\n",
    "        \n",
    "        left_imT = (left_imT-torch.mean(left_imT))/torch.std(left_imT)\n",
    "        right_imT = (right_imT-torch.mean(right_imT))/torch.std(right_imT)        \n",
    "        \n",
    "\n",
    "        left_feat = branch(left_imT)\n",
    "        right_feat = branch(right_imT)\n",
    "        \n",
    "        _,f,h,w = left_feat.shape\n",
    "        \n",
    "        cost_vol = np.zeros((max_disp+1,a_h,a_w))\n",
    "        cost_volT = Variable(Tensor(cost_vol))\n",
    "\n",
    "        #0 => max_disp => one less disp!\n",
    "        #python3 apparently cannot have 0 here for disp: right_shift = torch.cuda.FloatTensor(1,f,h,disp).fill_(0)  \n",
    "        for disp in range(0,max_disp+1):\n",
    "\n",
    "            if(disp == 0):\n",
    "                \n",
    "                sim_score = cos(left_feat, right_feat)\n",
    "                cost_volT[disp,:,:] = torch.squeeze(F.conv2d(torch.squeeze(sim_score).unsqueeze(0).unsqueeze(0), weights,padding = p))                \n",
    "            else:\n",
    "                right_shifted = torch.cuda.FloatTensor(1,f,h,w).fill_(0)                      \n",
    "                right_shift = torch.cuda.FloatTensor(1,f,h,disp).fill_(0)  \n",
    "                right_appended = torch.cat([right_shift,right_feat],3)\n",
    "\n",
    "                _,f,h_ap,w_ap = right_appended.shape\n",
    "                right_shifted[:,:,:,:] = right_appended[:,:,:,:(w_ap-disp)]\n",
    "                sim_score = cos(left_feat, right_shifted)\n",
    "                cost_volT[disp,:,:] = torch.squeeze(F.conv2d(torch.squeeze(sim_score).unsqueeze(0).unsqueeze(0), weights,padding = p))              \n",
    "\n",
    "    return cost_volT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCostVolRLBranch(branch, simB, left_im,right_im,max_disp):\n",
    "\n",
    "    \n",
    "    k_s = 19\n",
    "    p = 9\n",
    "    \n",
    "    w = np.ones((k_s,k_s)).astype(np.float32)\n",
    "    \n",
    "    weights = Tensor(w)\n",
    "    weights = weights.view(1, 1, k_s, k_s).repeat(1, 1, 1, 1)\n",
    "    \n",
    "    a_h, a_w,c = left_im.shape\n",
    "\n",
    "    left_im = np.transpose(left_im, (2,0,1)).astype(np.uint8)\n",
    "    right_im = np.transpose(right_im, (2,0,1)).astype(np.uint8)\n",
    "\n",
    "    \n",
    "    left_im = np.reshape(left_im, [1,c,a_h,a_w])\n",
    "    right_im = np.reshape(right_im, [1,c,a_h,a_w])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        left_imT = Variable(Tensor(left_im))\n",
    "        right_imT = Variable(Tensor(right_im))\n",
    "\n",
    "        left_imT = (left_imT-torch.mean(left_imT))/torch.std(left_imT)\n",
    "        right_imT = (right_imT-torch.mean(right_imT))/torch.std(right_imT)        \n",
    "        \n",
    "        left_feat = branch(left_imT)\n",
    "        right_feat = branch(right_imT)\n",
    "\n",
    "\n",
    "        _,f,h,w = left_feat.shape\n",
    "        cost_vol = np.zeros((max_disp+1,a_h,a_w))\n",
    "        \n",
    "        cost_volT = Variable(Tensor(cost_vol))\n",
    "\n",
    "        for disp in range(0,max_disp+1):\n",
    "\n",
    "            if(disp == 0):\n",
    "                sim_score = cos(left_feat, right_feat)\n",
    "                cost_volT[disp,:,:] = torch.squeeze(F.conv2d(torch.squeeze(sim_score).unsqueeze(0).unsqueeze(0), weights,padding = p)) \n",
    "            \n",
    "            else:    \n",
    "                left_shifted = torch.cuda.FloatTensor(1,f,h,w).fill_(0)\n",
    "                left_shift = torch.cuda.FloatTensor(1,f,h,disp).fill_(0)\n",
    "                left_appended = torch.cat([left_feat,left_shift],3)\n",
    "\n",
    "                _,f,h_ap,w_ap = left_appended.shape\n",
    "                left_shifted[:,:,:,:] = left_appended[:,:,:,disp:w_ap]\n",
    "            \n",
    "                sim_score = cos(left_shifted, right_feat)\n",
    "                cost_volT[disp,:,:] = torch.squeeze(F.conv2d(torch.squeeze(sim_score).unsqueeze(0).unsqueeze(0), weights,padding = p))\n",
    "                \n",
    "    return cost_volT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor = torch.cuda.FloatTensor\n",
    "cos = torch.nn.CosineSimilarity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#even further improve this by using pytorch!\n",
    "def LR_Check(first_output, second_output, dataset):    \n",
    "    \n",
    "    h,w = first_output.shape\n",
    "        \n",
    "    line = np.array(range(0, w))\n",
    "    idx_arr = np.matlib.repmat(line,h,1)    \n",
    "    \n",
    "    dif = idx_arr - first_output\n",
    "    \n",
    "    first_output[np.where(dif <= 0)] = 0\n",
    "    \n",
    "    first_output = first_output.astype(np.int)\n",
    "    second_output = second_output.astype(np.int)\n",
    "    dif = dif.astype(np.int)\n",
    "    \n",
    "    second_arr_reordered = np.array(list(map(lambda x, y: y[x], dif, second_output)))\n",
    "    \n",
    "    dif_LR = np.abs(second_arr_reordered - first_output)\n",
    "    first_output[np.where(dif_LR >= 1.1)] = 0\n",
    "    \n",
    "    if(dataset == 'MB'):\n",
    "        first_output[np.where(first_output <= 15.0)] = 0\n",
    "        \n",
    "    \n",
    "    first_output = first_output.astype(np.float32)\n",
    "    first_output[np.where(first_output == 0.0)] = np.nan\n",
    "    \n",
    "        \n",
    "    return first_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#even further improve this by using pytorch!\n",
    "def RL_Check(first_output, second_output, dataset):    \n",
    "    \n",
    "    h,w = first_output.shape\n",
    "        \n",
    "    line = np.array(range(0, w))\n",
    "    idx_arr = np.matlib.repmat(line,h,1)    \n",
    "    \n",
    "    dif = idx_arr + first_output\n",
    "    \n",
    "    dif[np.where(dif >= w)] = 0\n",
    "    \n",
    "    first_output = first_output.astype(np.int)\n",
    "    second_output = second_output.astype(np.int)\n",
    "    dif = dif.astype(np.int)\n",
    "    \n",
    "    second_arr_reordered = np.array(list(map(lambda x, y: y[x], dif, second_output)))\n",
    "    \n",
    "    dif_RL = np.abs(second_arr_reordered - first_output)\n",
    "    first_output[np.where(dif_RL >= 1.1)] = 0\n",
    "    \n",
    "    if(dataset == 'MB'):\n",
    "        first_output[np.where(first_output <= 15.0)] = 0\n",
    "\n",
    "    first_output = first_output.astype(np.float32)\n",
    "    first_output[np.where(first_output == 0.0)] = np.nan\n",
    "        \n",
    "    return first_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGT(epoch, avg_err):\n",
    "    nr = 0\n",
    "    gt_newlist = []\n",
    "    disp_newlist = []\n",
    "    #gtrl_newlist = []\n",
    "    nr_incons_tot = 0.0\n",
    "    \n",
    "    \n",
    "    avg_five_pe = 0.0\n",
    "    avg_four_pe = 0.0\n",
    "    avg_three_pe = 0.0\n",
    "    avg_two_pe = 0.0\n",
    "    avg_one_pe = 0.0\n",
    "    avg_pf_pe = 0.0      \n",
    "    \n",
    "    \n",
    "    #samples problem!!!! Fix that!!!\n",
    "    for i in range(0, len(left_list)):\n",
    "\n",
    "        max_disp = max_disp_list[i]\n",
    "        s_name = s_name_list[i]\n",
    "        \n",
    "        gt = gt_list[i]\n",
    "        \n",
    "        cost_vol = createCostVolBranch(branch, simB,left_list[i],right_list[i],max_disp)\n",
    "        cost_volRL = createCostVolRLBranch(branch, simB,left_list[i],right_list[i],max_disp)\n",
    "\n",
    "        disp = np.argmax(cost_vol.cpu().data.numpy(), axis=0) \n",
    "        dispRL = np.argmax(cost_volRL.cpu().data.numpy(), axis=0) \n",
    "        \n",
    "        five_pe, four_pe, three_pe, two_pe, one_pe, pf_pe = calcEPE(disp, gt)\n",
    "\n",
    "        avg_five_pe = avg_five_pe + five_pe\n",
    "        avg_four_pe = avg_four_pe +  four_pe\n",
    "        avg_three_pe = avg_three_pe + three_pe\n",
    "        avg_two_pe = avg_two_pe + two_pe\n",
    "        avg_one_pe = avg_one_pe + one_pe\n",
    "        avg_pf_pe = avg_pf_pe + pf_pe      \n",
    "\n",
    "        #writePFMcyt(out_folder +  s_name + '%06d_e%06f.pfm' %(epoch,two_pe),disp.astype(np.float32))\n",
    "                \n",
    "        #LR_Check sets certain values of disp to 0, should probably be a copy!\n",
    "        disp_s = LR_Check(disp, dispRL, 'NO')\n",
    "\n",
    "        #writePFMcyt(out_folder +  s_name + '%06d_e%06f.pfm' %(epoch,two_pe),disp.astype(np.float32))\n",
    "        \n",
    "\n",
    "        gt_newlist.append(disp_s)\n",
    "        disp_newlist.append(disp)\n",
    "        \n",
    "        nr_incons = np.count_nonzero(np.isnan(disp_s))\n",
    "        nr_incons_tot = nr_incons_tot + nr_incons\n",
    "        \n",
    "        #disp_srl = RL_Check(dispRL, disp, 'MB')\n",
    "        #gtrl_newlist.append(disp_srl)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #writePFMcyt(out_folder +  s_name + '%06d_e%06f.pfm' %(epoch,two_pe),disp.astype(np.float32))\n",
    "        #writePFMcyt(out_folder + s_name + '%06d_s.pfm' %epoch,disp_s) \n",
    "       # writePFMcyt(out_folder + s_name + '%06d_rl.pfm' %epoch,dispRL.astype(np.float32))         \n",
    "\n",
    "    \n",
    "    avg_four_pe = avg_four_pe / len(left_list)\n",
    "    avg_two_pe = avg_two_pe / len(left_list)\n",
    "    avg_one_pe = avg_one_pe / len(left_list)\n",
    "    avg_pf_pe = avg_pf_pe / len(left_list)\n",
    "\n",
    "    print(\"4-PE: {}\".format(avg_four_pe))\n",
    "    print(\"2-PE: {}\".format(avg_two_pe))\n",
    "    print(\"1-PE: {}\".format(avg_one_pe))\n",
    "    print(\"0.5-PE: {}\".format(avg_pf_pe))\n",
    "\n",
    "\n",
    "    #if(avg_err > nr_incons_tot):\n",
    "        #for j in range(0, len(left_list)):\n",
    "        \n",
    "        \n",
    "\n",
    "    return gt_newlist, nr_incons_tot, disp_newlist#, gtrl_newlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augm, flip left right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need the 2D-filter??\n",
    "def getGTWSimB(epoch, avg_err):\n",
    "    nr = 0\n",
    "    gt_newlist = []\n",
    "    disp_newlist = []\n",
    "    #gtrl_newlist = []\n",
    "    nr_incons_tot = 0.0\n",
    "    \n",
    "    \n",
    "    avg_five_pe = 0.0\n",
    "    avg_four_pe = 0.0\n",
    "    avg_three_pe = 0.0\n",
    "    avg_two_pe = 0.0\n",
    "    avg_one_pe = 0.0\n",
    "    avg_pf_pe = 0.0      \n",
    "    \n",
    "    \n",
    "    #samples problem!!!! Fix that!!!\n",
    "    for i in range(0, len(left_list)):\n",
    "\n",
    "        max_disp = max_disp_list[i]\n",
    "        s_name = s_name_list[i]\n",
    "        \n",
    "        gt = gt_list[i]\n",
    "        cost_volLT, cost_volRLT = createCostVolAllTogetherSimB(left_list[i],right_list[i],max_disp, False)\n",
    "        \n",
    "        cost_vol = np.squeeze(cost_volLT.cpu().data.numpy())\n",
    "        #somewhere between here and below, part of disp is set to 0!!\n",
    "        disp = np.argmax(cost_vol, axis=0)  \n",
    "        \n",
    "        five_pe, four_pe, three_pe, two_pe, one_pe, pf_pe = calcEPE(disp, gt)\n",
    "\n",
    "        avg_five_pe = avg_five_pe + five_pe\n",
    "        avg_four_pe = avg_four_pe +  four_pe\n",
    "        avg_three_pe = avg_three_pe + three_pe\n",
    "        avg_two_pe = avg_two_pe + two_pe\n",
    "        avg_one_pe = avg_one_pe + one_pe\n",
    "        avg_pf_pe = avg_pf_pe + pf_pe      \n",
    "\n",
    "        #writePFMcyt(out_folder +  s_name + '%06d_e%06f.pfm' %(epoch,two_pe),disp.astype(np.float32))\n",
    "        \n",
    "        cost_volRL = np.squeeze(cost_volRLT.cpu().data.numpy())\n",
    "        dispRL = np.argmax(cost_volRL, axis=0)        \n",
    "        \n",
    "        #LR_Check sets certain values of disp to 0, should probably be a copy!\n",
    "        disp_s = LR_Check(disp, dispRL, 'NO')\n",
    "\n",
    "        #writePFMcyt(out_folder +  s_name + '%06d_e%06f.pfm' %(epoch,two_pe),disp.astype(np.float32))\n",
    "        \n",
    "\n",
    "        gt_newlist.append(disp_s)\n",
    "        disp_newlist.append(disp)\n",
    "        \n",
    "        nr_incons = np.count_nonzero(np.isnan(disp_s))\n",
    "        nr_incons_tot = nr_incons_tot + nr_incons\n",
    "        \n",
    "        #disp_srl = RL_Check(dispRL, disp, 'MB')\n",
    "        #gtrl_newlist.append(disp_srl)\n",
    "        \n",
    "        \n",
    "        \n",
    "        ##writePFMcyt(out_folder +  s_name + '%06d_e%06f.pfm' %(epoch,two_pe),disp.astype(np.float32))\n",
    "        #writePFMcyt(out_folder + s_name + '%06d_s.pfm' %epoch,disp_s) \n",
    "        #writePFMcyt(out_folder + s_name + '%06d_rl.pfm' %epoch,dispRL.astype(np.float32))         \n",
    "\n",
    "    \n",
    "    avg_four_pe = avg_four_pe / len(left_list)\n",
    "    avg_two_pe = avg_two_pe / len(left_list)\n",
    "    avg_one_pe = avg_one_pe / len(left_list)\n",
    "    avg_pf_pe = avg_pf_pe / len(left_list)\n",
    "\n",
    "    print(\"4-PE: {}\".format(avg_four_pe))\n",
    "    print(\"2-PE: {}\".format(avg_two_pe))\n",
    "    print(\"1-PE: {}\".format(avg_one_pe))\n",
    "    print(\"0.5-PE: {}\".format(avg_pf_pe))\n",
    "\n",
    "\n",
    "    #if(avg_err > nr_incons_tot):\n",
    "        #for j in range(0, len(left_list)):\n",
    "        \n",
    "        \n",
    "\n",
    "    return gt_newlist, nr_incons_tot, disp_newlist#, gtrl_newlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBatchRL(gt_cons_cpy):\n",
    "    \n",
    "    batch_xl = np.zeros((batch_size,3,patch_size,patch_size))\n",
    "    batch_xr_pos = np.zeros((batch_size,3,patch_size,patch_size))\n",
    "    batch_xr_neg = np.zeros((batch_size,3,patch_size,patch_size))\n",
    "    \n",
    "    for el in range(batch_size):\n",
    "        \n",
    "        if(el % 10 == 0):\n",
    "            \n",
    "            ridx = np.random.randint(0,len(gt_cons_cpy),1)\n",
    "            left_im = left_list[ridx[0]]\n",
    "            right_im = right_list[ridx[0]]\n",
    "            gt_im = gt_cons_cpy[ridx[0]]\n",
    "        \n",
    "        \n",
    "        h,w,c = left_im.shape\n",
    "        r_h = 0\n",
    "        r_w = 0\n",
    "        d = 0\n",
    "#        print('Draw for random position')\n",
    "        #also check height! should not draw corner pixels!!\n",
    "        while True:\n",
    "            r_h = random.sample(range(ps_h,h-(ps_h+1)), 1)\n",
    "            \n",
    "            r_w = random.sample(range(ps_h,w-(ps_h+1)),1)   \n",
    "            \n",
    "            if(not np.isnan(gt_im[r_h,r_w])):\n",
    "                d = int(np.round(gt_im[r_h,r_w]))\n",
    "                if((r_w[0]-ps_h+d-1) >= 0):\n",
    "                     if((r_w[0]+(ps_h+1)+d+1) <= w):\n",
    "                        break\n",
    "        \n",
    "        d = int(np.round(gt_im[r_h,r_w]))\n",
    "                \n",
    "        cur_right = right_im[r_h[0]-ps_h:r_h[0]+(ps_h+1), r_w[0]-ps_h:r_w[0]+(ps_h+1),:]\n",
    "        #choose offset\n",
    "        \n",
    "        o_pos = 0                \n",
    "        cur_left_pos = left_im[r_h[0]-ps_h:r_h[0]+(ps_h+1), (r_w[0]-ps_h+d+o_pos):(r_w[0]+(ps_h+1)+d+o_pos),:]\n",
    "\n",
    "        \n",
    "        #should not be too close to real match!\n",
    "        o_neg = 0\n",
    "        while True:\n",
    "            #range 6-8??? range(2,6)\n",
    "            o_neg = random.sample(range(r_low,r_high), 1)\n",
    "            if np.random.randint(-1, 1) == -1:\n",
    "                o_neg = -o_neg[0]\n",
    "            else:\n",
    "                o_neg = o_neg[0]\n",
    "            #try without d-+1   and(o_neg != (d-1)) and(o_neg != (d+1))\n",
    "            if((o_neg != d) and ((r_w[0]-ps_h+d+o_neg) > 0)  and ((r_w[0]+(ps_h+1)+d+o_neg) < w)):\n",
    "                break\n",
    "        \n",
    "        \n",
    "        cur_left_neg = left_im[r_h[0]-ps_h:r_h[0]+(ps_h+1), (r_w[0]-ps_h+d+o_neg):(r_w[0]+(ps_h+1)+d+o_neg),:]\n",
    "        \n",
    "        \n",
    "        \n",
    "        batch_xl[el,:,:,:] =  np.transpose(cur_right, (2,0,1)).astype(np.uint8)\n",
    "        batch_xr_pos[el,:,:,:] = np.transpose(cur_left_pos, (2,0,1)).astype(np.uint8)\n",
    "        batch_xr_neg[el,:,:,:] = np.transpose(cur_left_neg, (2,0,1)).astype(np.uint8)\n",
    "            \n",
    "    return batch_xl, batch_xr_pos, batch_xr_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_list, right_list, gt_list,max_disp_list, s_name_list = loadMB(input_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#branch.load_state_dict(torch.load('/media/HDD/Self_supervised_BCKUP/weights/NEW/branch/BEST_SMALLER/mb_60f40s_best3400e3974438.000000'))\n",
    "#simB.load_state_dict(torch.load('/media/HDD/Self_supervised_BCKUP/weights/NEW/simB/BEST_SMALLER/mb_60f40s_best3400e3974438.000000'))\n",
    "#left_list, right_list, gt_list,max_disp_list, s_name_list = loadMB(input_folder)\n",
    "\n",
    "#avg_2PE = TestMB(branch, simB, input_folder, 0,out_folder,True,True,True, True)\n",
    "\n",
    "#print(avg_2PE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gt_newlist, disp_newlist = getGT()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try add warping loss again???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getShiftedLeft(disp, left):\n",
    "    h,w,c = left.shape\n",
    "    im_empty = np.zeros((h,w,c))\n",
    "    for h_ in range(0,h):\n",
    "        for w_ in range(0,w):\n",
    "            if(w_ - disp[h_,w_] > 0):\n",
    "                im_empty[h_,w_,:] = left[h_,w_- disp[h_,w_].astype(np.uint8),:]\n",
    "            else:\n",
    "                continue\n",
    "    return im_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#right_shift = getShiftedLeft(disp_s,right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#l1_loss = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#right_shift_list = []\n",
    "\n",
    "\n",
    "#for z in range(0,len(gt_newlist)):\n",
    "    \n",
    "#    right_shifted = getShiftedLeft(disp_newlist[z],right_list[z])\n",
    "#    right_shift_list.append(right_shifted)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure()\n",
    "#plt.imshow(gt_newlist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure()\n",
    "#plt.imshow(right_shift_list[0].astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBatchShift(left_list, right_shifted_list):\n",
    "    \n",
    "    batch_right_shifted = np.zeros((batch_size,3,patch_size,patch_size))\n",
    "    batch_left = np.zeros((batch_size,3,patch_size,patch_size))\n",
    "    \n",
    "    for el in range(batch_size):\n",
    "        \n",
    "        if(el % 10 == 0):\n",
    "            \n",
    "            ridx = np.random.randint(0,len(right_shifted_list),1)\n",
    "            left_im = left_list[ridx[0]]\n",
    "            right_im = right_shifted_list[ridx[0]].astype(np.uint8)\n",
    "                    \n",
    "        \n",
    "        h,w,c = left_im.shape\n",
    "        r_h = 0\n",
    "        r_w = 0\n",
    "        \n",
    "        while True:\n",
    "            r_h = random.sample(range(ps_h,h-(ps_h+1)), 1)\n",
    "            \n",
    "            r_w = random.sample(range(ps_h,w-(ps_h+1)),1)   \n",
    "            if((r_w[0]-ps_h-1) >= 0):\n",
    "                if((r_w[0]+(ps_h+1)+1) <= w):\n",
    "                    break\n",
    "                        \n",
    "        cur_left = left_im[r_h[0]-ps_h:r_h[0]+(ps_h+1), r_w[0]-ps_h:r_w[0]+(ps_h+1),:]\n",
    "        cur_right_shifted = right_im[r_h[0]-ps_h:r_h[0]+(ps_h+1), (r_w[0]-ps_h):(r_w[0]+(ps_h+1)),:]        \n",
    "        \n",
    "        \n",
    "        batch_left[el,:,:,:] =  np.transpose(cur_left, (2,0,1)).astype(np.uint8)\n",
    "        batch_right_shifted[el,:,:,:] = np.transpose(cur_right_shifted, (2,0,1)).astype(np.uint8)\n",
    "            \n",
    "    return batch_left, batch_right_shifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TestMB(branch, simB, input_folder, epoch, output_folder,filtered,lr_check,fill_incons, save)\n",
    "\n",
    "\n",
    "\n",
    "#avg_2PE = TestMB(branch, simB, input_folder, 0,out_folder,True,True,True, True)\n",
    "\n",
    "#with FlickR, GRSS and drivingStereo\n",
    "#disp_s, disp, dispRL = TestImage(branch, simB, fn_left, fn_right, max_disp, filtered, lr_check, dataset)\n",
    "\n",
    "#gt_newlist, avg_2PE,disp_newlist = getGT()\n",
    "#gt_newlist, disp_newlist = getGT()\n",
    "\n",
    "\n",
    "#print(avg_2PE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGRSS():\n",
    "    inp_folder = '/media/HDD/Self-Sup_Stereo/OwnStereoNW/Out/GRSS/pack1_ext2/'\n",
    "    left_f = glob.glob(inp_folder + 'left*')\n",
    "    right_f = glob.glob(inp_folder + 'right*')\n",
    "    maxdisp_f = glob.glob(inp_folder + 'maxdisp*') \n",
    "    gt_f =        glob.glob(inp_folder + 'gt*')\n",
    "    \n",
    "    left_f = sorted(left_f)\n",
    "    right_f = sorted(right_f)\n",
    "    maxdisp_f = sorted(maxdisp_f)\n",
    "    gt_f = sorted(gt_f)\n",
    "    \n",
    "    left_list = []\n",
    "    right_list = []\n",
    "    maxdisp_list = []\n",
    "    s_name_list = []\n",
    "    gt_list = []\n",
    "    \n",
    "    for i in range(len(left_f)):\n",
    "        \n",
    "        cur_left = cv2.imread(left_f[i])\n",
    "        cur_right = cv2.imread(right_f[i])\n",
    "        \n",
    "        left_list.append(cur_left)\n",
    "        right_list.append(cur_right)\n",
    "        \n",
    "        f = open(maxdisp_f[i],'r')\n",
    "        mdisp_s = f.read()\n",
    "\n",
    "        max_disp = int(float(mdisp_s))\n",
    "        maxdisp_list.append(max_disp)\n",
    "        \n",
    "        s_name_list.append(str(i))\n",
    "        \n",
    "        gt, _ = readPFM(gt_f[i])\n",
    "        \n",
    "        gt_list.append(gt)\n",
    "        \n",
    "    \n",
    "    return left_list, right_list, maxdisp_list, s_name_list, gt_list \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "\n",
    "def TestGRSS(output_folder):\n",
    "    \n",
    "    avg_five_pe = 0.0\n",
    "    avg_four_pe = 0.0 \n",
    "    avg_three_pe = 0.0 \n",
    "    avg_two_pe = 0.0\n",
    "    avg_one_pe = 0.0\n",
    "    avg_pf_pe = 0.0\n",
    "    nr_incons_tot = 0.0\n",
    "    \n",
    "    left_list, right_list, maxdisp_list, s_name_list, gt_list = loadGRSS()    \n",
    "    \n",
    "    left_list = glob.glob('/media/HDD/Self-Sup_Stereo/OwnStereoNW/Out/GRSS/pack1_ext2/left*')\n",
    "    right_list = glob.glob('/media/HDD/Self-Sup_Stereo/OwnStereoNW/Out/GRSS/pack1_ext2/right*')\n",
    "\n",
    "    left_list = sorted(left_list)\n",
    "    right_list = sorted(right_list)\n",
    "    \n",
    "    for i in range(0,len(left_list)):   #len(left_list)\n",
    "        \n",
    "        disp, cost_vol = TestImage(branch, simB, left_list[i], right_list[i], maxdisp_list[i], True, False, None)\n",
    "\n",
    "        #disp_s, disp, dispRL = TestImage(branch, simB, left_list[i], right_list[i], maxdisp_list[i], True, True, None)\n",
    "\n",
    "        #s_name = left_list[i].split('/')[-2]\n",
    "        ##########################\n",
    "        \n",
    "        \n",
    "        #disp_arr = np.array(disp_s)\n",
    "        #im_disp = Image.fromarray(disp_arr) \n",
    "        #im_disp = np.dstack((im_disp, im_disp, im_disp)).astype(np.uint8)    \n",
    "\n",
    "        #h,w = disp_arr.shape\n",
    "\n",
    "        #shifted = cv2.pyrMeanShiftFiltering(im_disp, 7, 7)\n",
    "\n",
    "        #gray = cv2.cvtColor(shifted, cv2.COLOR_BGR2GRAY)\n",
    "        #thresh = cv2.threshold(gray, 0, 1,\n",
    "        #cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "        ##cv2.imwrite(im_to_save + 'bilat_and_med_mask.png',thresh * 255)\n",
    "\n",
    "        #disp_filled = FillIncons(thresh, disp_arr)\n",
    "        #disp_filled = np.array(disp_filled)   \n",
    "        \n",
    "        five_pe, four_pe, three_pe, two_pe, one_pe, pf_pe = calcEPE(disp, gt_list[i])        \n",
    "\n",
    "        #five_pe, four_pe, three_pe, two_pe, one_pe, pf_pe = calcEPE(disp_filled, gt_list[i])        \n",
    "\n",
    "        avg_five_pe = avg_five_pe + five_pe\n",
    "        avg_four_pe = avg_four_pe +  four_pe\n",
    "        avg_three_pe = avg_three_pe + three_pe\n",
    "        avg_two_pe = avg_two_pe + two_pe\n",
    "        avg_one_pe = avg_one_pe + one_pe\n",
    "        avg_pf_pe = avg_pf_pe + pf_pe \n",
    "        \n",
    "        \n",
    "        with open(output_folder +\"%06i.bin\" %i, \"wb\") as binary_file:\n",
    "            binary_file.write(cost_vol)    \n",
    "        \n",
    "        \n",
    "        writePFMcyt(output_folder +  '%06i_e%06f.pfm' %(i,two_pe),disp.astype(np.float32))\n",
    "        #writePFMcyt(output_folder + '%06i_e%06f_s.pfm' %(i,two_pe) ,disp_s.astype(np.float32)) \n",
    "        #writePFMcyt(output_folder + '%06i_e%06f_rl.pfm' %(i,two_pe) ,dispRL.astype(np.float32)) \n",
    "        #writePFMcyt(output_folder +  '%06i_e%06f_filled.pfm' %(i,two_pe) ,disp_filled.astype(np.float32))\n",
    "        \n",
    "        \n",
    "    avg_four_pe = avg_four_pe / len(left_list)\n",
    "    avg_two_pe = avg_two_pe / len(left_list)\n",
    "    avg_one_pe = avg_one_pe / len(left_list)\n",
    "    avg_pf_pe = avg_pf_pe / len(left_list)\n",
    "    \n",
    "    print(\"4-PE: {}\".format(avg_four_pe))\n",
    "    print(\"2-PE: {}\".format(avg_two_pe))\n",
    "    print(\"1-PE: {}\".format(avg_one_pe))\n",
    "    print(\"0.5-PE: {}\".format(avg_pf_pe))\n",
    "    return avg_two_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#left_list, right_list, max_disp_list, s_name_list, gt_list = loadGRSS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#branch.load_state_dict(torch.load('/media/HDD/Self-Sup_Stereo/OwnStereoNW/weights/NEW/branch/BEST_SMALLER/mb_60f40s_best3400e3974438.000000'))\n",
    "#simB.load_state_dict(torch.load('/media/HDD/Self-Sup_Stereo/OwnStereoNW/weights/NEW/simB/BEST_SMALLER/mb_60f40s_best3400e3974438.000000'))\n",
    "\n",
    "#branch.load_state_dict(torch.load('/media/HDD/Self-Sup_Stereo/OwnStereoNW/weights/NEW/branch/BEST/mb_60f40s_best1800e3916060.000000'))\n",
    "#simB.load_state_dict(torch.load('/media/HDD/Self-Sup_Stereo/OwnStereoNW/weights/NEW/simB/BEST/mb_60f40s_best1800e3916060.000000'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#branch.load_state_dict(torch.load('/media/HDD/Self-Sup_Stereo/OwnStereoNW/weights/NEW/branch/BEST/mb_60f40s_best1800e3916060.000000'))\n",
    "#simB.load_state_dict(torch.load('/media/HDD/Self-Sup_Stereo/OwnStereoNW/weights/NEW/simB/BEST/mb_60f40s_best1800e3916060.000000'))\n",
    "\n",
    "#avg_2PE =TestGRSS('/home/dominik/Desktop/RAFTStereo/StereoSlices/SadaNet/t/')\n",
    "\n",
    "\n",
    "#print(avg_2PE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestFlickr(output_folder):\n",
    "    \n",
    "    left_list = glob.glob('/home/dominik/Desktop/RAFTStereo/StereoSlices/RaftStereo/Flickr/*/*L*')\n",
    "    right_list = glob.glob('/home/dominik/Desktop/RAFTStereo/StereoSlices/RaftStereo/Flickr/*/*R*')\n",
    "\n",
    "    left_list = sorted(left_list)\n",
    "    right_list = sorted(right_list)\n",
    "    \n",
    "    for i in range(len(left_list)):\n",
    "\n",
    "\n",
    "        disp_s, disp, dispRL = TestImage(branch, simB, left_list[i], right_list[i], 250, True, True, None)\n",
    "\n",
    "        s_name = left_list[i].split('/')[-2]\n",
    "        ##########################\n",
    "        \n",
    "        \n",
    "        disp_arr = np.array(disp_s)\n",
    "        im_disp = Image.fromarray(disp_arr) \n",
    "        im_disp = np.dstack((im_disp, im_disp, im_disp)).astype(np.uint8)    \n",
    "\n",
    "        h,w = disp_arr.shape\n",
    "\n",
    "        shifted = cv2.pyrMeanShiftFiltering(im_disp, 7, 7)\n",
    "\n",
    "        gray = cv2.cvtColor(shifted, cv2.COLOR_BGR2GRAY)\n",
    "        thresh = cv2.threshold(gray, 0, 1,\n",
    "        cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "        ##cv2.imwrite(im_to_save + 'bilat_and_med_mask.png',thresh * 255)\n",
    "\n",
    "        disp_filled = FillIncons(thresh, disp_arr)\n",
    "        disp_filled = np.array(disp_filled)        \n",
    "\n",
    "        #\n",
    "        writePFMcyt(output_folder +  s_name + '.pfm' ,disp.astype(np.float32))\n",
    "        writePFMcyt(output_folder + s_name + '_s.pfm' ,disp_s.astype(np.float32)) \n",
    "        writePFMcyt(output_folder + s_name + '_rl.pfm' ,dispRL.astype(np.float32)) \n",
    "        writePFMcyt(output_folder +  s_name + '_filled.pfm' ,disp_filled.astype(np.float32))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TestFlickr('/home/dominik/Desktop/RAFTStereo/StereoSlices/SadaNet/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "branch.load_state_dict(torch.load('/media/HDD/Self-Sup_Stereo/OwnStereoNW/weights/NEW/branch/BEST_SMALLER/mb_60f40s_best3400e3974438.000000'))\n",
    "simB.load_state_dict(torch.load('/media/HDD/Self-Sup_Stereo/OwnStereoNW/weights/NEW/simB/BEST_SMALLER/mb_60f40s_best3400e3974438.000000'))\n",
    "\n",
    "#branch.load_state_dict(torch.load('/media/HDD/Self_supervised_BCKUP/weights/branch/mb_60f40s_best5400e3910538.000000'))\n",
    "#simB.load_state_dict(torch.load('/media/HDD/Self_supervised_BCKUP/weights/simB/mb_60f40s_best5400e3910538.000000'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#left_list, right_list, max_disp_list, s_name_list, gt_list = loadGRSS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipes: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2383/21970483.py:13: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  first_output = first_output.astype(np.int)\n",
      "/tmp/ipykernel_2383/21970483.py:14: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  second_output = second_output.astype(np.int)\n",
      "/tmp/ipykernel_2383/21970483.py:15: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dif = dif.astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teddy: 128\n",
      "Playroom: 165\n",
      "Motorcycle: 140\n",
      "Piano: 130\n",
      "Vintage: 380\n",
      "Recycle: 130\n",
      "MotorcycleE: 140\n",
      "Jadeplant: 320\n",
      "Playtable: 145\n",
      "Shelves: 120\n",
      "ArtL: 128\n",
      "PianoL: 130\n",
      "Adirondack: 145\n",
      "PlaytableP: 145\n",
      "4-PE: 14.85792368669987\n",
      "2-PE: 19.763447127091485\n",
      "1-PE: 32.675165799385454\n",
      "0.5-PE: 58.650207587895025\n",
      "Nr Incons: 3313979.0\n"
     ]
    }
   ],
   "source": [
    "left_list, right_list, gt_list,max_disp_list, s_name_list = loadMB(input_folder)\n",
    "\n",
    "avg_2PE = TestMB(branch, simB, input_folder, 0,out_folder,True,True,True, True)\n",
    "\n",
    "#print(avg_2PE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_newlist,nr_incons_tot, disp_newlist = getGT(0,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#already trained over night\n",
    "#branch.load_state_dict(torch.load('/media/HDD/Self_supervised_BCKUP/weights/branch/mb_60f40s_best3700e50516450.000000'))\n",
    "#simB.load_state_dict(torch.load('/media/HDD/Self_supervised_BCKUP/weights/simB/mb_60f40s_best3700e50516450.000000'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#add bad slices later!!\n",
    "#(avgerr * len(list) + avgerrbad * len(badlist) ) / (len(list) + len(badlist))\n",
    "\n",
    "#avg_2PE =TestGRSS('/home/dominik/Desktop/RAFTStereo/StereoSlices/SadaNet/t/')\n",
    "#print(avg_2PE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#lr = 0.00001\n",
    "#save_weights = 10\n",
    "\n",
    "params = list(branch.parameters()) + list(simB.parameters())\n",
    "\n",
    "optimizer_G = optim.Adam(params, lr)\n",
    "\n",
    "\n",
    "best_err = 10000000000\n",
    "\n",
    "early_stopping_count = 0\n",
    "\n",
    "for i in range(1000000000000000000000):\n",
    "    \n",
    "    \n",
    "    epoch_loss = 0.0\n",
    "    for cur_batch in range(nr_batches): \n",
    "        \n",
    "        #reset gradients\n",
    "        optimizer_G.zero_grad()\n",
    "        \n",
    "\n",
    "        batch_xl, batch_xr_pos, batch_xr_neg = getBatch(gt_newlist)\n",
    "\n",
    "        \n",
    "        bs, c, h, w = batch_xl.shape\n",
    "\n",
    "        xl = Variable(Tensor(batch_xl.astype(np.uint8)))\n",
    "        \n",
    "        xr_pos = Variable(Tensor(batch_xr_pos.astype(np.uint8)))\n",
    "        xr_neg = Variable(Tensor(batch_xr_neg.astype(np.uint8)))\n",
    "        \n",
    "        xl = (xl-torch.mean(xl))/torch.std(xl)\n",
    "        xr_pos = (xr_pos-torch.mean(xr_pos))/torch.std(xr_pos)      \n",
    "        xr_neg = (xr_neg-torch.mean(xr_neg))/torch.std(xr_neg) \n",
    "    \n",
    "        left_out = branch(xl)\n",
    "        right_pos_out = branch(xr_pos)\n",
    "        right_neg_out = branch(xr_neg)\n",
    "        \n",
    "        \n",
    "\n",
    "        sp = simB(torch.cat((left_out, right_pos_out),dim=1))\n",
    "        sn = simB(torch.cat((left_out, right_neg_out),dim=1))        \n",
    "        \n",
    "        batch_loss = my_hinge_loss(sp, sn)\n",
    "        batch_loss = batch_loss.mean()\n",
    "        \n",
    "        batch_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        epoch_loss = epoch_loss + batch_loss\n",
    "\n",
    "    \n",
    "    epoch_loss = epoch_loss/nr_batches\n",
    "    \n",
    "    if(i % save_weights == 0):\n",
    "        if(i > 0):\n",
    "            print(\"EPOCH: {} loss: {}\".format(i,epoch_loss))\n",
    "\n",
    "            gt_newlist, avg_2PE,disp_newlist = getGTWSimB(i, best_err)\n",
    "            \n",
    "\n",
    "            if(avg_2PE < best_err):\n",
    "\n",
    "                early_stopping_count = 0\n",
    "\n",
    "                print(colored(\"NEW BP: {}\".format(avg_2PE), 'green', attrs=['bold']))\n",
    "                torch.save(branch.state_dict(), save_folder_branch + model_name + '_best%04i' %(i) + 'e%04f' %(avg_2PE)) \n",
    "                torch.save(simB.state_dict(), save_folder_simb + model_name + '_best%04i' %(i) + 'e%04f' %(avg_2PE)) \n",
    "                best_err = avg_2PE\n",
    "\n",
    "            else:\n",
    "\n",
    "                print(\"got worse\")\n",
    "                print(avg_2PE)\n",
    "                early_stopping_count = early_stopping_count + 1\n",
    "        \n",
    "        \n",
    "        if(early_stopping_count >= 20):\n",
    "            \n",
    "            \n",
    "            \n",
    "            print(\"Early-stop Epoch: {}\".format(i))\n",
    "            print('----------------------------------')\n",
    "            \n",
    "            \n",
    "            \n",
    "            break\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
